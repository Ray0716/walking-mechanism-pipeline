{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Watt2T1A1', 0], ['Steph1T3', 2], ['Watt1T1A1', 19], ['Steph3T2A2', 26], ['Watt1T3A2', 37], ['Steph2T2A1', 39], ['Steph3T1A2', 73], ['Watt2T2A2', 82], ['Watt1T2A1', 90], ['Steph2T1A1', 110], ['Steph3T2A1', 111], ['Watt1T1A2', 125], ['Watt2T1A2', 133], ['Steph1T2', 135], ['Steph1T1', 137], ['Watt1T3A1', 139], ['Watt1T2A2', 149], ['Watt2T2A1', 163], ['Steph3T1A1', 169], ['Steph2T1A2', 176], ['Steph2T2A2', 177]]\n",
      "['RRRR', 'RRRP', 'RRPR', 'PRPR', 'Watt2T1A1', 'Steph1T3', 'Watt1T1A1', 'Steph3T2A2', 'Watt1T3A2', 'Steph2T2A1', 'Steph3T1A2', 'Watt2T2A2', 'Watt1T2A1', 'Steph2T1A1', 'Steph3T2A1', 'Watt1T1A2', 'Watt2T1A2', 'Steph1T2', 'Steph1T1', 'Watt1T3A1', 'Watt1T2A2', 'Watt2T2A1', 'Steph3T1A1', 'Steph2T1A2', 'Steph2T2A2']\n",
      "[49, 64, 155, 175, 0, 2, 19, 26, 37, 39, 73, 82, 90, 110, 111, 125, 133, 135, 137, 139, 149, 163, 169, 176, 177]\n",
      "RRRR [0, 0, 0, 0, 1]\n",
      "RRRP [0, 0, 0, 0, 1, 0]\n",
      "RRPR [0, 0, 0, 0, 1, 0, 0]\n",
      "PRPR [0, 0, 0, 0, 1]\n",
      "Watt2T1A1 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph1T3 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Watt1T1A1 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph3T2A2 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Watt1T3A2 [0, 0, 0, 0, 0, 0, 1]\n",
      "Steph2T2A1 [0, 0, 0, 0, 1, 0, 0]\n",
      "Steph3T1A2 [0, 0, 0, 0, 1, 0, 0]\n",
      "Watt2T2A2 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Watt1T2A1 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph2T1A1 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph3T2A1 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Watt1T1A2 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Watt2T1A2 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph1T2 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph1T1 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Watt1T3A1 [0, 0, 0, 0, 0, 0, 1]\n",
      "Watt1T2A2 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Watt2T2A1 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph3T1A1 [0, 0, 0, 0, 1, 0, 0]\n",
      "Steph2T1A2 [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Steph2T2A2 [0, 0, 0, 0, 1, 0, 0]\n",
      "Updated couplerCurveIndex: [4, 4, 4, 4, 7, 7, 7, 7, 6, 4, 4, 7, 7, 7, 7, 7, 7, 7, 7, 6, 7, 7, 4, 7, 4]\n",
      "/gpfs/home/raytang/walking-dataset-generator-old-simulator/Image-method-Synthesis-main/outputs-6bar/Steph3T2A2 /gpfs/home/raytang/walking-dataset-generator-old-simulator/Image-method-Synthesis-main/outputs-6bar/Steph3T2A2-npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "from glob import glob\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from itertools import islice\n",
    "from PIL import Image\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Headless simulator version\n",
    "index = 7 # local server index \n",
    "#API_ENDPOINT = 'http://localhost:400' + str(index) + '/simulation' # NOT THE LS VERSION\n",
    "API_ENDPOINT = 'http://localhost:400' + str(1) + '/simulation' # NOT THE LS VERSION\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "batchCount = 25 # Send this number of samples to MotionGen each time \n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)\n",
    "\n",
    "# Search for \"stephenson\" or \"watt\" in the JSON file and collect their names and indices\n",
    "json_path = \"KV_468_062324.json\"\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "matches = []\n",
    "for idx, name in enumerate(data):\n",
    "    lname = name.lower()\n",
    "    if \"step\" in lname or \"watt\" in lname:\n",
    "        matches.append([name, idx])\n",
    "print(matches)\n",
    "\n",
    "\n",
    "# Things for 4 bar \n",
    "mechType = index\n",
    "types = ['RRRR', 'RRRP', 'RRPR', 'PRPR']\n",
    "for mechanism in matches:\n",
    "    types.append(mechanism[0])\n",
    "print(types)\n",
    "# ['RRRR', 'RRRP', 'RRPR', 'PRPR', 'Watt2T1A1', 'Steph1T3', 'Watt1T1A1', 'Steph3T2A2', 'Watt1T3A2', 'Steph2T2A1', 'Steph3T1A2', 'Watt2T2A2', 'Watt1T2A1', 'Steph2T1A1', 'Steph3T2A1', 'Watt1T1A2', 'Watt2T1A2', 'Steph1T2', 'Steph1T1', 'Watt1T3A1', 'Watt1T2A2', 'Watt2T2A1', 'Steph3T1A1', 'Steph2T1A2', 'Steph2T2A2']\n",
    "\n",
    "# Create a directory in outputs-6bar for each type in types\n",
    "'''\n",
    "for t in types:\n",
    "    if t in ('RRRR', 'RRRP', 'RRPR', 'PRPR'):\n",
    "        continue\n",
    "    dir_path = os.path.abspath(\"./outputs-6bar/\" + t)\n",
    "    os.makedirs(dir_path, exist_ok=True)'''\n",
    "\n",
    "\n",
    "\n",
    "typeIndex = [49, 64, 155, 175] # to avoid confusion from any other type\n",
    "for mechanism in matches:\n",
    "    typeIndex.append(mechanism[1])\n",
    "\n",
    "print(typeIndex)\n",
    "# [49, 64, 155, 175, 0, 2, 19, 26, 37, 39, 73, 82, 90, 110, 111, 125, 133, 135, 137, 139, 149, 163, 169, 176, 177]\n",
    "\n",
    "\n",
    "#couplerCurveIndex = [4, 4, 4, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
    "\n",
    "\n",
    "#confirm that all c values are 1 at index 7 for 6 bars\n",
    "\n",
    "bsi = \"BSIdict_468_062324_3.json\"\n",
    "with open(bsi, \"r\") as b:\n",
    "    data = json.load(b)\n",
    "\n",
    "for key in types:\n",
    "    if key in data:\n",
    "        c_value = (data)[key].get(\"c\")\n",
    "        print(key, c_value)\n",
    "\n",
    "# Update couplerCurveIndex so that for each type, its value is the index of the number 1 in the c_value list from BSIdict\n",
    "couplerCurveIndex = []\n",
    "for key in types:\n",
    "    if key in data:\n",
    "        c_value = data[key].get(\"c\")\n",
    "        if isinstance(c_value, list) and 1 in c_value:\n",
    "            couplerCurveIndex.append(c_value.index(1))\n",
    "        else:\n",
    "            couplerCurveIndex.append(4)  # fallback default\n",
    "    else:\n",
    "        couplerCurveIndex.append(4)      # fallback default\n",
    "print(\"Updated couplerCurveIndex:\", couplerCurveIndex)\n",
    "# Updated couplerCurveIndex: [4, 4, 4, 4, 7, 7, 7, 7, 6, 4, 4, 7, 7, 7, 7, 7, 7, 7, 7, 6, 7, 7, 4, 7, 4]\n",
    "\n",
    "\n",
    "savePointNumber = [5, 6, 7, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] #len of c arrat acording to BSIdict\n",
    "needAddtional = [False, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False] # notice that when true, some of the points can change its position randomly \n",
    "#initStates = np.load(\"./npy-inputs/\" + 'RandPos-.npy')\n",
    "\n",
    "initStates = np.load(\"/gpfs/scratch/raytang/walking-dataset-generator-old-simulator/Image-method-Synthesis-main/npy-inputs/RandPos-.npy\")\n",
    "errCtr = 0\n",
    "batch = []\n",
    "batchSaveStr = []\n",
    "batchSaveNpyStr = []\n",
    "\n",
    "\n",
    "# The transformation \n",
    "#np.save(saveDir + name + ' ' + types[index], param)\n",
    "saveDir = os.path.abspath(\"./outputs-6bar/\" + types[index] )\n",
    "saveDirNpy = os.path.abspath(\"./outputs-6bar/\" + types[index] + \"-npy\")\n",
    "print(saveDir, saveDirNpy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good old ones \n",
    "\n",
    "def isValid(seq):\n",
    "    if len(seq.shape) == 2:\n",
    "        isVal = np.var(seq[:,0]) <= 5e-3 and np.var(seq[:,1]) <= 5e-3\n",
    "    else:\n",
    "        isVal = len(seq) == 0 or np.var(seq) <= 5e-3\n",
    "\n",
    "    if isVal:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_pca_inclination(qx, qy, ax=None, label=''):\n",
    "    \"\"\" Performs the PCA\n",
    "        Return transformation matrix\n",
    "    \"\"\"\n",
    "    cx = np.mean(qx)\n",
    "    cy = np.mean(qy)\n",
    "    covar_xx = np.sum((qx - cx)*(qx - cx))/len(qx)\n",
    "    covar_xy = np.sum((qx - cx)*(qy - cy))/len(qx)\n",
    "    covar_yx = np.sum((qy - cy)*(qx - cx))/len(qx)\n",
    "    covar_yy = np.sum((qy - cy)*(qy - cy))/len(qx)\n",
    "    covar = np.array([[covar_xx, covar_xy],[covar_yx, covar_yy]])\n",
    "    eig_val, eig_vec= np.linalg.eig(covar)\n",
    "\n",
    "    # Inclination of major principal axis w.r.t. x axis\n",
    "    if eig_val[0] > eig_val[1]:\n",
    "        phi= np.arctan2(eig_vec[1,0], eig_vec[0,0])\n",
    "    else:\n",
    "        phi= np.arctan2(eig_vec[1,1], eig_vec[0,1])\n",
    "\n",
    "    return phi\n",
    "\n",
    "\n",
    "def get_normalize_curve(jd, steps=None, rotations=1, normalize=True, transformParas=None):\n",
    "    jd = np.array(jd)\n",
    "    joint_data_n, x_mean, y_mean, denom, phi = [], None, None, None, None\n",
    "    if isValid(jd):\n",
    "        if steps:\n",
    "            sample_indices = np.linspace(0, jd.shape[0]-1, steps, dtype=np.int32)\n",
    "            jd = jd[sample_indices,:]\n",
    "        if normalize:\n",
    "            if not transformParas:\n",
    "                x_mean = np.mean(jd[:,0], axis=0, keepdims=True)\n",
    "                y_mean = np.mean(jd[:,1], axis=0, keepdims=True)\n",
    "            else:\n",
    "                x_mean, y_mean, denom, phi = transformParas\n",
    "            jd[:,0] = jd[:,0] - x_mean\n",
    "            jd[:,1] = jd[:,1] - y_mean\n",
    "\n",
    "            if not transformParas:\n",
    "                denom = np.sqrt(np.var(jd[:,0], axis=0, keepdims=True) + np.var(jd[:,1], axis=0, keepdims=True))\n",
    "                denom = np.expand_dims(denom, axis=1)\n",
    "            jd = jd / denom\n",
    "            t = 0\n",
    "        if not transformParas:\n",
    "            phi = -get_pca_inclination(jd[:,0], jd[:,1])\n",
    "        jd[:,0], jd[:, 1] = rotate_curve(jd, phi)\n",
    "        for tt in range(rotations):\n",
    "            joint_data_n.append(jd.copy())\n",
    "            if rotations > 1:\n",
    "                jd[:,0], jd[:,1] = rotate_curve(jd, t)\n",
    "                t = 2*np.pi/rotations\n",
    "\n",
    "    return joint_data_n, x_mean, y_mean, denom, phi\n",
    "\n",
    "\n",
    "def rotate_curve(cur, theta):\n",
    "    cpx = cur[:,0]*np.cos(theta) - cur[:,1]*np.sin(theta)\n",
    "    cpy = cur[:,0]*np.sin(theta) + cur[:,1]*np.cos(theta)\n",
    "    return cpx, cpy\n",
    "\n",
    "\n",
    "def digitize_seq(nums, minlim, maxlim, bin_size=64):\n",
    "    bins = np.linspace(minlim, maxlim, bin_size-1)\n",
    "    nums_indices = np.digitize(nums, bins)\n",
    "    return nums_indices\n",
    "\n",
    "\n",
    "def get_normalize_joint_data_wrt_one_curve(joint_data, ref_ind = 4):\n",
    "    ''' input s = [num_curves, num_points, 2]\n",
    "    '''\n",
    "    joint_data_n = []\n",
    "    s = np.array(joint_data)\n",
    "    if isValid(s[ref_ind]):\n",
    "        x_mean = np.mean(s[ref_ind:ref_ind+1,:,0], axis=1, keepdims=True)\n",
    "        y_mean = np.mean(s[ref_ind:ref_ind+1,:,1], axis=1, keepdims=True)\n",
    "        s[:,:,0] = s[:,:,0] - x_mean\n",
    "        s[:,:,1] = s[:,:,1] - y_mean\n",
    "        denom = np.sqrt(np.var(s[ref_ind:ref_ind+1,:,0], axis=1, keepdims=True) + np.var(s[ref_ind:ref_ind+1,:,1], axis=1, keepdims=True))\n",
    "        denom = np.expand_dims(denom, axis=2) #is this scale? \n",
    "        s = s / denom\n",
    "        phi = -get_pca_inclination(s[ref_ind:ref_ind+1,:,0], s[ref_ind:ref_ind+1,:,1])\n",
    "        for i in range(s.shape[0]):\n",
    "            s[i,:,0], s[i,:,1] = rotate_curve(s[i], phi)\n",
    "    else:\n",
    "        return s, [None, None, None, None], False\n",
    "\n",
    "    # s has a shape of (j_num, state, dim)\n",
    "    return s, [x_mean[0][0], y_mean[0][0], denom[0][0][0], phi], True # tx, ty, scaling, rotation angle \n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# There are some other necessary transformations. (x_mean, y_mean, phi, denom) are from get_normalize_curve. \n",
    "##############################################################################################\n",
    "def get_image_from_point_cloud(points, xylim, im_size, inverted = True, label=None):\n",
    "    mat = np.zeros((im_size, im_size, 1), dtype=np.uint8)\n",
    "    x = digitize_seq(points[:,0], -xylim, xylim, im_size)\n",
    "    if inverted:\n",
    "        y = digitize_seq(points[:,1]*-1, -xylim, xylim, im_size)\n",
    "        mat[y, x, 0] = 1\n",
    "    else:\n",
    "        y = digitize_seq(points[:,1], -xylim, xylim, im_size)\n",
    "        mat[x, y, 0] = 1\n",
    "    return mat\n",
    "\n",
    "\n",
    "def process_mech_102723(jointData, ref_ind, im_size = 64, xylim = 3.5, inverted = True, swapAxes = True):\n",
    "    paras = None\n",
    "\n",
    "    # It is possible the jointData format is (angles, joint, (x, y)). \n",
    "    # You should put a True if this happens. (This is how files are saved).\n",
    "    # I literally don't understand why I saved jointData with a shape of (angles, joint, (x, y)) \n",
    "    if swapAxes:\n",
    "        jointData = np.swapaxes(jointData, 0, 1)\n",
    "\n",
    "    # This converts all \n",
    "    jointData, paras, success = get_normalize_joint_data_wrt_one_curve(jointData, ref_ind= ref_ind)\n",
    "\n",
    "    # jointData format from now on becomes np.array with a shape of (joint, curve_length, dimension)\n",
    "    jointData = np.array(jointData)\n",
    "\n",
    "    if success:\n",
    "        # get binaryImage \n",
    "        jd = jointData[ref_ind]\n",
    "        mat = get_image_from_point_cloud(jd, xylim=xylim, im_size=im_size, inverted=inverted)\n",
    "        return mat, paras, success\n",
    "    else: \n",
    "        return None, None, success\n",
    "\n",
    "\n",
    "def calc_dist(coord):\n",
    "    # Calculate differences using broadcasting\n",
    "    diffs = coord[:, np.newaxis, :] - coord[np.newaxis, :, :]\n",
    "    squared_dists = np.sum(diffs ** 2, axis=2)\n",
    "\n",
    "    # Extract the upper triangle indices where i < j\n",
    "    i, j = np.triu_indices(len(coord), k=1)\n",
    "    dist_arr = np.sqrt(squared_dists[i, j])\n",
    "    dist_arr = dist_arr/min(dist_arr)\n",
    "    return np.round(dist_arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################## \n",
    "# An even better version of normalization method (it can be slower sometimes)\n",
    "# Uses reflection correction (contributed by the paper Geometric Invariant Curve and Surface Normalization)  \n",
    "# Thanks to Zhijie who noticed these two can be used together. \n",
    "##############################################################################################\n",
    "\n",
    "def rotate_curve(curve, phi):\n",
    "    infunction_scale = 100\n",
    "    # curve is scaled 100 times for numerical accuracy \n",
    "    # incoming curve shape: (n,2)\n",
    "    x = curve[:, 0] * infunction_scale\n",
    "    y = curve[:, 1] * infunction_scale\n",
    "    # Compute the rotated coordinates\n",
    "    x_rotated = x * np.cos(phi) - y * np.sin(phi)\n",
    "    y_rotated = x * np.sin(phi) + y * np.cos(phi)\n",
    "    # Combine the rotated coordinates into a new curve\n",
    "    rotated_curve = np.column_stack((x_rotated, y_rotated))\n",
    "    return rotated_curve/infunction_scale\n",
    "\n",
    "\n",
    "def center_data(X):\n",
    "    \"\"\" Center the data by subtracting the mean of each column.\n",
    "        Return the translated X and the translation matrix \n",
    "    \"\"\"\n",
    "    m = np.mean(X, axis=0) # (n, 2)\n",
    "    return X - m, np.matrix([[1, 0, -m[0]], [0, 1, -m[1]], [0, 0, 1]]) # equal to XP this is a translation matrix tranposed  \n",
    "\n",
    "\n",
    "def scale_data(X, scaling = 0): \n",
    "    \"\"\" Scale the data according to two different metrics \n",
    "        If scaling == 0 (default), scaling method is normalization (average distance 1)\n",
    "        If otherwise, scaling method is standardization to a certain scale \n",
    "        Return the scaled X, and the scaling matrix. \n",
    "    \"\"\"\n",
    "    if scaling == 0:\n",
    "        # use variance. \n",
    "        denom = np.sqrt(np.var(X[:,0]) + np.var(X[:,1]))\n",
    "        scaled_curve = X /denom\n",
    "        ScaleMat = np.matrix([[1/denom, 0, 0], [0, 1/denom, 0], [0, 0, 1]])\n",
    "    else:\n",
    "        # Compute the maximum distance from the origin \n",
    "        max_distance = np.max(np.linalg.norm(X, axis=1))\n",
    "        scaled_curve = X * scaling / max_distance\n",
    "        ScaleMat = np.matrix([[scaling/max_distance, 0, 0], [0, scaling/max_distance, 0], [0, 0, 1]])\n",
    "    return scaled_curve, ScaleMat\n",
    "\n",
    "\n",
    "def rotate_data(X, tol = 1e-4, randinit = False): \n",
    "    \"\"\" Performs the PCA and determines rotation angle phi \n",
    "        More precisely it is snapping the greatest principal axis to the X-axis. \n",
    "        Return the rotated X and the rotation matrix \n",
    "    \"\"\"\n",
    "    phiInit = 0\n",
    "    if randinit:\n",
    "        phiInit = np.random.rand() * math.pi * 2 \n",
    "\n",
    "    rotationMatInit = np.matrix([\n",
    "        [np.cos(phiInit), -np.sin(phiInit), 0], \n",
    "        [np.sin(phiInit), np.cos(phiInit), 0],\n",
    "        [0, 0, 1] \n",
    "    ])\n",
    "\n",
    "    X0 = rotate_curve(X, phiInit)\n",
    "    cx = np.mean(X0[:,0])\n",
    "    cy = np.mean(X0[:,1])\n",
    "    covar_xx = np.sum((X0[:,0] - cx)*(X0[:,0] - cx))/X0.shape[0]\n",
    "    covar_xy = np.sum((X0[:,0] - cx)*(X0[:,1] - cy))/X0.shape[0]\n",
    "    covar_yx = np.sum((X0[:,1] - cy)*(X0[:,0] - cx))/X0.shape[0]\n",
    "    covar_yy = np.sum((X0[:,1] - cy)*(X0[:,1] - cy))/X0.shape[0]\n",
    "    covar = np.array([[covar_xx, covar_xy],[covar_yx, covar_yy]])\n",
    "\n",
    "    if np.abs(np.linalg.det(covar)) < tol:\n",
    "        phi = 0 # why rotate anyway? \n",
    "    else:\n",
    "        eig_val, eig_vec= np.linalg.eig(covar) \n",
    "        # Inclination of major principal axis w.r.t. x axis\n",
    "        # Enforcing the cross-product of the two eigenvectors to be greater than 0. \n",
    "        # Not necessary, but it looks clean to do so. \n",
    "        # Eigenvector matrix: [a, b], det = crossproduct of b x a\n",
    "        if np.linalg.det(eig_vec) > 0:\n",
    "            eig_vec[0,:] = -eig_vec[0,:] # enforcing a x b > 0 \n",
    "        if eig_val[0] > eig_val[1]:\n",
    "            phi= np.arctan2(eig_vec[1,0], eig_vec[0,0])\n",
    "        else:\n",
    "            phi= np.arctan2(eig_vec[1,1], eig_vec[0,1])\n",
    "    rotated_curve = rotate_curve(X0, phi)\n",
    "    rotationMat = np.matrix([\n",
    "        [np.cos(phi), -np.sin(phi), 0], \n",
    "        [np.sin(phi), np.cos(phi), 0],\n",
    "        [0, 0, 1] \n",
    "    ])\n",
    "\n",
    "    return rotated_curve, np.matmul(rotationMat, rotationMatInit)\n",
    "\n",
    "\n",
    "def reflect_data(X):\n",
    "    \"\"\" Computes the third order moment and determines the reflections \n",
    "        The data must be rotated before this step. \n",
    "\n",
    "    \"\"\"\n",
    "    # Reflection normalization \n",
    "    x_scaled = X[:, 0]\n",
    "    y_scaled = X[:, 1]\n",
    "\n",
    "    # see paper Geometric Invariant Curve and Surface Normalization\n",
    "    # compute the 3rd-order moments \n",
    "    m12 = np.sum((x_scaled**1)*(y_scaled**2))\n",
    "    m21 = np.sum((x_scaled**2)*(y_scaled**1))\n",
    "    signm12 = np.sign(m12)\n",
    "    signm21 = np.sign(m21)\n",
    "    if np.abs(signm12) < 1e-5:\n",
    "        signm12 = 1\n",
    "    if np.abs(signm21) < 1e-5:\n",
    "        signm21 = 1\n",
    "\n",
    "    reflectionMat = np.array(\n",
    "        [[signm12, 0],\n",
    "         [0, signm21]]\n",
    "    ) \n",
    "\n",
    "    if np.abs(m12) > np.abs(m21):\n",
    "        reflectionMat = np.matmul(np.array([[0,1],[1,0]]), reflectionMat)\n",
    "\n",
    "    reflected_Curve = np.matmul(reflectionMat, np.array(X).T).T\n",
    "    reflectionMat = np.matrix(\n",
    "        [[reflectionMat[0,0], reflectionMat[0,1], 0], \n",
    "         [reflectionMat[1,0], reflectionMat[1,1], 0], \n",
    "         [0, 0, 1]\n",
    "        ]\n",
    "    ) \n",
    "\n",
    "    return reflected_Curve, reflectionMat\n",
    "\n",
    "\n",
    "# Digitization \n",
    "def digitize_seq(nums, minlim, maxlim, bin_size=64):\n",
    "    bins = np.linspace(minlim, maxlim, bin_size-1)\n",
    "    nums_indices = np.digitize(nums, bins)\n",
    "    return nums_indices\n",
    "\n",
    "\n",
    "def get_image_from_point_cloud(points, xylim, im_size, inverted = True, label=None):\n",
    "    mat = np.zeros((im_size, im_size, 1), dtype=np.uint8)\n",
    "    x = digitize_seq(points[:,0], -xylim, xylim, im_size)\n",
    "    if inverted:\n",
    "        y = digitize_seq(points[:,1]*-1, -xylim, xylim, im_size)\n",
    "        mat[y, x, 0] = 1\n",
    "    else:\n",
    "        y = digitize_seq(points[:,1], -xylim, xylim, im_size)\n",
    "        mat[x, y, 0] = 1\n",
    "    return mat\n",
    "\n",
    "\n",
    "# Returns normalized curve, Transformation matrix, and Success (if determinant is greater than tolerance for numerical stability)\n",
    "def normalize_data_122223(X, scaling = 0, tol = 1e-8, maxiter = 2):\n",
    "    X1, M1 = center_data(X) \n",
    "    X1, M2 = scale_data(X1, scaling = scaling)\n",
    "    X1, M3 = rotate_data(X1)\n",
    "    X1, M4 = reflect_data(X1)\n",
    "    M = M4*M3*M2*M1 # This is the transformation matrix \n",
    "\n",
    "    detVal = np.abs(np.linalg.det(M))\n",
    "    if detVal*scaling < tol:\n",
    "        for i in range(maxiter):\n",
    "            X1, M1 = center_data(X1)\n",
    "            X1, M2 = scale_data(X1, scaling = scaling)\n",
    "            X1, M3 = rotate_data(X1, randinit= True)\n",
    "            X1, M4 = reflect_data(X1)\n",
    "            if np.abs(np.linalg.det(M)) > tol or detVal*10 < np.abs(np.linalg.det(M)):\n",
    "                break\n",
    "    return X1, M4*M3*M2*M1, np.abs(np.linalg.det(M)) > tol\n",
    "\n",
    "\n",
    "def matmul_jd(jd, mat):\n",
    "    # input should be (..., ,2)\n",
    "    # the operation: \n",
    "    jd = np.array(jd)\n",
    "    oldshape = jd.shape\n",
    "    njd= np.reshape(jd, (-1, 2))\n",
    "    hc1= np.ones((njd.shape[0], 1))\n",
    "    njd=np.matrix(np.concatenate([njd, hc1], axis = 1)).transpose()\n",
    "    njd=np.array((mat*njd).transpose())[:,0:2].reshape(oldshape)\n",
    "    return njd\n",
    "\n",
    "\n",
    "# Processing \n",
    "# THIS IS THE MAIN FUNCTION YOU NEED (second version) \n",
    "# Input is the mechanism and coupler point index (ref_ind), Output is matImg, [<two transformation matrix instead of six parameters>], and Success. \n",
    "# NOTICE 1: the parameter has SIX parameters, not four (x, y translation, angle and scale). The addtional parameters are reflectionMat, seqReversed (refrlection matrix and whether or not the sequence is reverse in order)\n",
    "# NOTICE 2: the transformation matrices are numpy arrays. You need to convert them to lists before converting them into .json format objects. \n",
    "# I suggest you save the a, b, c, d, e, f values in the matrix. \n",
    "# A transformation matrix is shaped as: \n",
    "# [[a, c, e]\n",
    "#  [b, d, f]\n",
    "#  [0, 0, 1]]\n",
    "def process_mech_051524(jointData, ref_ind, im_size = 64, xylim = 3.5, inverted = True):\n",
    "    # New JD shape is always (states, joints, dimensions)\n",
    "    paras = None\n",
    "    # get matrices according to curve. \n",
    "    nc, mat, success = normalize_data_122223(jointData[:,ref_ind,:], scaling = 3.5)\n",
    "    NR_MG = mat # transform original position to normalized position # NR_MG * jointData = normalized joint data\n",
    "    MG_NR = np.linalg.inv(NR_MG) \n",
    "\n",
    "    if success:\n",
    "        # get binaryImage # rohit's choice on what to save \n",
    "        paras = NR_MG\n",
    "        matImg = get_image_from_point_cloud(nc, xylim=xylim, im_size=im_size, inverted=inverted)\n",
    "        return matImg, paras, success\n",
    "    else: \n",
    "        return None, None, success\n",
    "\n",
    "    \n",
    "def calc_dist(coord):\n",
    "    # Calculate differences using broadcasting\n",
    "    diffs = coord[:, np.newaxis, :] - coord[np.newaxis, :, :]\n",
    "    squared_dists = np.sum(diffs ** 2, axis=2)\n",
    "\n",
    "    # Extract the upper triangle indices where i < j\n",
    "    i, j = np.triu_indices(len(coord), k=1)\n",
    "    dist_arr = np.sqrt(squared_dists[i, j])\n",
    "    dist_arr = dist_arr/min(dist_arr)\n",
    "    return np.round(dist_arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3920.000 -0.001 5.393 1.748 -8.786 2.079 5.023 -4.854 0.423 5.406 -1.882 -1.388 0.241 -0.285 0.455 0.899 0.000 1.000\n"
     ]
    }
   ],
   "source": [
    "def format_floats_to_string(float_list):\n",
    "    formatted_strings = [f\"{value:.3f}\" for value in float_list]\n",
    "    result_string = ' '.join(formatted_strings)\n",
    "    return ' ' + result_string\n",
    "\n",
    "# Example usage\n",
    "float_values = [3920, -1.000e-03, 5.393e+00, 1.748e+00, -8.786e+00, 2.079e+00, 5.023e+00, -4.854e+00, 4.230e-01, 5.406e+00, -1.882e+00, -1.388e+00, 0.241, -0.285, 0.455, 0.899, 0.0, 1.0]\n",
    "\n",
    "formatted_string = format_floats_to_string(float_values)\n",
    "print(formatted_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRRR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 861/500000 [00:03<30:45, 270.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/software/Anaconda/envs/Jupyter/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2487570/3568655347.py\", line None, in <module>\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/software/Anaconda/envs/Jupyter/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/software/Anaconda/envs/Jupyter/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/software/Anaconda/envs/Jupyter/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/software/Anaconda/envs/Jupyter/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/software/Anaconda/envs/Jupyter/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 773, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/software/Anaconda/envs/Jupyter/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 536, in format_record\n",
      "    assert isinstance(frame_info.lineno, int)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "normFailCtr = 0\n",
    "\n",
    "mechType = 0\n",
    "# ['RRRR', 'RRRP', 'RRPR', 'PRPR', 'Watt2T1A1', 'Steph1T3', 'Watt1T1A1', 'Steph3T2A2', 'Watt1T3A2', 'Steph2T2A1', 'Steph3T1A2', 'Watt2T2A2', 'Watt1T2A1', 'Steph2T1A1', 'Steph3T2A1', 'Watt1T1A2', 'Watt2T1A2', 'Steph1T2', 'Steph1T1', 'Watt1T3A1', 'Watt1T2A2', 'Watt2T2A1', 'Steph3T1A1', 'Steph2T1A2', 'Steph2T2A2']\n",
    "saveDir = os.path.abspath(\"./outputs-6bar/\" + types[mechType] )\n",
    "saveDirNpy = os.path.abspath(\"./outputs-6bar/\" + types[mechType] + \"-npy\")\n",
    "\n",
    "NUM_MECHS = 500000\n",
    "#mechtype=6\n",
    "\n",
    "#saveDir = os.path.abspath(\"./outputs-6bar/\" + types[mechType] )\n",
    "#\n",
    "# Prefer Savitzky-Golay if available\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def has_sharp_edges(coords, curvature_threshold=15.0, smoothing_sigma=1.0):\n",
    "    \"\"\"\n",
    "    Detect if a 2D curve has sharp edges using curvature.\n",
    "\n",
    "    Parameters:\n",
    "    - coords: np.array of shape (N,2) representing the curve points.\n",
    "    - curvature_threshold: float, curvature value above which a point is considered a sharp corner.\n",
    "    - smoothing_sigma: float, optional Gaussian smoothing to reduce numerical noise.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if curve has sharp edges, False otherwise\n",
    "    - curvature: np.array of curvature values along the curve (optional, useful for plotting)\n",
    "    \"\"\"\n",
    "    if smoothing_sigma > 0:\n",
    "        x = gaussian_filter1d(coords[:,0], sigma=smoothing_sigma)\n",
    "        y = gaussian_filter1d(coords[:,1], sigma=smoothing_sigma)\n",
    "    else:\n",
    "        x = coords[:,0]\n",
    "        y = coords[:,1]\n",
    "\n",
    "    dx = np.gradient(x)\n",
    "    dy = np.gradient(y)\n",
    "    ddx = np.gradient(dx)\n",
    "    ddy = np.gradient(dy)\n",
    "\n",
    "    curvature = np.abs(dx * ddy - dy * ddx) / (dx**2 + dy**2)**1.5\n",
    "\n",
    "    return np.any(curvature > curvature_threshold), curvature\n",
    "\n",
    "\n",
    "def resample_uniform(points, M):\n",
    "    # points: (N,2) numpy\n",
    "    # Return M points uniformly along arc length\n",
    "    dif = np.diff(points, axis=0)\n",
    "    seglen = np.sqrt((dif**2).sum(axis=1))\n",
    "    s = np.concatenate(([0], np.cumsum(seglen)))\n",
    "    total = s[-1]\n",
    "    if total == 0:\n",
    "        return np.repeat(points[:1], M, axis=0)\n",
    "    s_uniform = np.linspace(0, total, M)\n",
    "    x = np.interp(s_uniform, s, points[:,0])\n",
    "    y = np.interp(s_uniform, s, points[:,1])\n",
    "    return np.column_stack((x, y))\n",
    "\n",
    "\n",
    "def pca_align(points):\n",
    "    # points: (N,2) numpy array (assumes centered or will center here)\n",
    "    pts = points - np.mean(points, axis=0)\n",
    "    # Compute principal components via SVD\n",
    "    U, S, VT = np.linalg.svd(pts, full_matrices=False)\n",
    "    pcs = VT.T  # columns are principal directions\n",
    "    # rotate so first PC aligns with x-axis\n",
    "    rotated = pts @ pcs\n",
    "    return rotated, pcs  # rotated coords, principal direction basis\n",
    "# eps slope used to be 0.0015\n",
    "\n",
    "\n",
    "\n",
    "def detect_flat_via_pca(points, K_keep=12, N_resample=512, eps_slope=0.0075, min_fraction=1/4):\n",
    "    # points: original coupler coords\n",
    "    pts = resample_uniform(points, N_resample)\n",
    "    rotated, pcs = pca_align(pts)\n",
    "    # rotated[:,1] is the coordinate perpendicular to main axis (height)\n",
    "    dy = np.gradient(rotated[:,1])\n",
    "    flat_mask = np.abs(dy) < eps_slope\n",
    "    # find the longest contiguous run\n",
    "    from itertools import groupby\n",
    "    runs = [sum(1 for _ in g) for val,g in groupby(flat_mask) if val]\n",
    "    max_run = max(runs) if runs else 0\n",
    "    flat_fraction = max_run / len(flat_mask)\n",
    "    is_flat_enough = flat_fraction >= min_fraction\n",
    "    # orientation: angle of first PC relative to x-axis\n",
    "    # pcs[:,0] is first PC in original frame\n",
    "    first_pc = pcs[:,0]\n",
    "    angle = np.arctan2(first_pc[1], first_pc[0])  # radians\n",
    "\n",
    "    max_run = 0\n",
    "    run_indices = []\n",
    "    current_run = []\n",
    "\n",
    "    for i, is_flat in enumerate(flat_mask):\n",
    "        if is_flat:\n",
    "            current_run.append(i)\n",
    "            if len(current_run) > max_run:\n",
    "                max_run = len(current_run)\n",
    "                run_indices = current_run.copy()\n",
    "        else:\n",
    "            current_run = []\n",
    "\n",
    "    return {\n",
    "        'flat_fraction': float(flat_fraction),\n",
    "        'is_flat_enough': bool(is_flat_enough),\n",
    "        'orientation_rad': float(angle),\n",
    "        'orientation_deg': float(np.degrees(angle)),\n",
    "        'max_run': int(max_run),\n",
    "        'N': int(len(flat_mask)),\n",
    "        'flat_indices': np.array(run_indices, dtype=int), \n",
    "        'pts': pts,\n",
    "    }\n",
    "\n",
    "\n",
    "def ground_clearance_check(path_coords, joint_coords, flat_indices):\n",
    "    if len(flat_indices) == 0:\n",
    "        print(\"No flat indices provided.\")\n",
    "        return False\n",
    "    flat_pts = path_coords[flat_indices]\n",
    "    # Fit line to flat portion\n",
    "    m, b = np.polyfit(flat_pts[:,0], flat_pts[:,1], 1)\n",
    "\n",
    "    # Create line values across full x-range\n",
    "    x_line = np.linspace(path_coords[:,0].min(), path_coords[:,0].max(), 200)\n",
    "    y_line = m * x_line + b\n",
    "\n",
    "    # Signed distance of path points to the line\n",
    "\n",
    "    d_path = path_coords[:,1] - (m*path_coords[:,0] + b)\n",
    "\n",
    "    majority_sign = np.sign(np.sum(d_path))\n",
    "\n",
    "    if majority_sign == 0:\n",
    "\n",
    "        majority_sign = 1  # fallback if perfectly balanced\n",
    "\n",
    "\n",
    "\n",
    "    # Signed distance for joints\n",
    "\n",
    "    d_joints = joint_coords[:,1] - (m*joint_coords[:,0] + b)\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    # Debug print\n",
    "\n",
    "    all_clear = np.all(np.sign(d_joints) == majority_sign)\n",
    "\n",
    "    return all_clear\n",
    "\n",
    "\n",
    "def plot_flat_fit_with_joints(path_coords, flat_indices, joint_coords, title=\"Flat Fit Check\"):\n",
    "    \"\"\"\n",
    "    Plot the full curve, flat segment, best-fit line, and joint coordinates\n",
    "    with indices labeled.\n",
    "    \"\"\"\n",
    "    if len(flat_indices) == 0:\n",
    "        print(\"No flat indices provided.\")\n",
    "        return\n",
    "    \n",
    "    flat_pts = path_coords[flat_indices]\n",
    "\n",
    "    # Fit line to flat portion\n",
    "    m, b = np.polyfit(flat_pts[:,0], flat_pts[:,1], 1)\n",
    "\n",
    "    # Create line values across full x-range\n",
    "    x_line = np.linspace(path_coords[:,0].min(), path_coords[:,0].max(), 200)\n",
    "    y_line = m * x_line + b\n",
    "\n",
    "    # Signed distance of path points to the line\n",
    "\n",
    "    d_path = path_coords[:,1] - (m*path_coords[:,0] + b)\n",
    "\n",
    "    majority_sign = np.sign(np.sum(d_path))\n",
    "\n",
    "    if majority_sign == 0:\n",
    "\n",
    "        majority_sign = 1  # fallback if perfectly balanced\n",
    "\n",
    "\n",
    "\n",
    "    # Signed distance for joints\n",
    "\n",
    "    d_joints = joint_coords[:,1] - (m*joint_coords[:,0] + b)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot original curve\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.plot(path_coords[:,0], path_coords[:,1], 'b-', label='Full curve')\n",
    "    plt.plot(flat_pts[:,0], flat_pts[:,1], 'ro', label='Flat segment')\n",
    "    plt.plot(x_line, y_line, 'k--', label='Best fit line (flat)')\n",
    "\n",
    "    # Plot joints with colors depending on clearance\n",
    "\n",
    "    for i, (x, y) in enumerate(joint_coords):\n",
    "        if np.sign(d_joints[i]) == majority_sign:\n",
    "            plt.scatter(x, y, c='g', marker='x', s=80)  # green if correct side\n",
    "        else:\n",
    "            plt.scatter(x, y, c='r', marker='x', s=80)  # red if wrong side\n",
    "        plt.text(x, y, str(i), fontsize=9, ha='right', va='bottom')\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    # Debug print\n",
    "\n",
    "    all_clear = np.all(np.sign(d_joints) == majority_sign)\n",
    "\n",
    "    print(f\"Line slope m = {m:.4f}, intercept b = {b:.4f}\")\n",
    "\n",
    "    print(f\"Majority sign = {majority_sign}\")\n",
    "\n",
    "    print(f\"Joint distances = {d_joints}\")\n",
    "\n",
    "    print(f\"Ground clearance OK? {all_clear}\")\n",
    "\n",
    "def save_flat_fit_with_joints(path_coords, flat_indices, joint_coords, save_dir, filename):\n",
    "    \"\"\"\n",
    "    Same as plot_flat_fit_with_joints, but saves the plot to a directory instead of displaying or printing.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(flat_indices) == 0:\n",
    "        return\n",
    "    \n",
    "    flat_pts = path_coords[flat_indices]\n",
    "\n",
    "    # Fit line to flat portion\n",
    "    m, b = np.polyfit(flat_pts[:,0], flat_pts[:,1], 1)\n",
    "\n",
    "    # Create line values across full x-range\n",
    "    x_line = np.linspace(path_coords[:,0].min(), path_coords[:,0].max(), 200)\n",
    "    y_line = m * x_line + b\n",
    "\n",
    "    # Signed distance of path points to the line\n",
    "    d_path = path_coords[:,1] - (m*path_coords[:,0] + b)\n",
    "    majority_sign = np.sign(np.sum(d_path))\n",
    "    if majority_sign == 0:\n",
    "        majority_sign = 1  # fallback if perfectly balanced\n",
    "\n",
    "    # Signed distance for joints\n",
    "    d_joints = joint_coords[:,1] - (m*joint_coords[:,0] + b)\n",
    "\n",
    "    # Plot original curve\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.plot(path_coords[:,0], path_coords[:,1], 'b-', label='Full curve')\n",
    "    plt.plot(flat_pts[:,0], flat_pts[:,1], 'ro', label='Flat segment')\n",
    "    plt.plot(x_line, y_line, 'k--', label='Best fit line (flat)')\n",
    "\n",
    "    # Plot joints with colors depending on clearance\n",
    "    for i, (x, y) in enumerate(joint_coords):\n",
    "        if np.sign(d_joints[i]) == majority_sign:\n",
    "            plt.scatter(x, y, c='g', marker='x', s=80)  # green if correct side\n",
    "        else:\n",
    "            plt.scatter(x, y, c='r', marker='x', s=80)  # red if wrong side\n",
    "        plt.text(x, y, str(i), fontsize=9, ha='right', va='bottom')\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.title(f\"coords:{filename}\")\n",
    "\n",
    "    # Ensure save_dir exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # Generate a filename\n",
    "    \n",
    "    filename = f\"{filename}.png\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "def has_self_intersections(coords):\n",
    "    line = LineString(coords)\n",
    "    return not line.is_simple  # False if self-crossing\n",
    "\n",
    "\n",
    "\n",
    "def is_closed(pts):\n",
    "    # Check if path is open or closed\n",
    "    start_pt = pts[0]\n",
    "    end_pt = pts[-1]\n",
    "    path_dist = np.linalg.norm(end_pt - start_pt)\n",
    "    is_closed = path_dist < 0.1\n",
    "    return is_closed\n",
    "\n",
    "def str_to_coords(s):\n",
    "    s = str(s)\n",
    "    nums = [float(x) for x in s.strip().split()]\n",
    "    return [[nums[j], nums[j+1]] for j in range(0, len(nums), 2)]\n",
    "\n",
    "def is_walking(coords):\n",
    "\n",
    "    pca_output = detect_flat_via_pca(normalized_coords)\n",
    "\n",
    "    sharp, kappa = has_sharp_edges(normalized_coords, curvature_threshold=150.0)\n",
    "\n",
    "    if pca_output['is_flat_enough'] and is_closed(normalized_coords) and (not sharp):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "numCoords = 5 # the number of joints, for 4 bars - 5 joints\n",
    "#             0         1       2       3      4             5           6             7            8          9              10            11            12            13            14           15           16           17            18         19          20           21           22            23            24            \n",
    "# mechtypes: ['RRRR', 'RRRP', 'RRPR', 'PRPR', 'Watt2T1A1', 'Steph1T3', 'Watt1T1A1', 'Steph3T2A2', 'Watt1T3A2', 'Steph2T2A1', 'Steph3T1A2', 'Watt2T2A2', 'Watt1T2A1', 'Steph2T1A1', 'Steph3T2A1', 'Watt1T1A2', 'Watt2T1A2', 'Steph1T2', 'Steph1T1', 'Watt1T3A1', 'Watt1T2A2', 'Watt2T2A1', 'Steph3T1A1', 'Steph2T1A2', 'Steph2T2A2'] (4 and 6 bars)\n",
    "for index in range(0, 25): # change this to range(0, 4) for 4-bar and range(5, 25) for 6-bar\n",
    "    mechType = index\n",
    "    print(types[mechType])\n",
    "    if mechType <= 3:\n",
    "        saveDir = os.path.abspath(\"./outputs-4bar/\" + types[mechType] )\n",
    "        saveDirNpy = os.path.abspath(\"./outputs-4bar/\" + types[mechType] + \"-npy\")\n",
    "        saveDirWalking = os.path.abspath(\"./outputs-4bar/walking_\" + types[mechType])\n",
    "        saveDirWalkingPlot = os.path.abspath(\"./outputs-4bar/walking_plot_\" + types[mechType])\n",
    "\n",
    "        numCoords = 5\n",
    "    else:\n",
    "        saveDir = os.path.abspath(\"./outputs-6bar/\" + types[mechType] )\n",
    "        saveDirNpy = os.path.abspath(\"./outputs-6bar/\" + types[mechType] + \"-npy\")\n",
    "        saveDirWalking = os.path.abspath(\"./outputs-6bar/walking_\" + types[mechType])\n",
    "        saveDirWalkingPlot = os.path.abspath(\"./outputs-6bar/walking_plot_\" + types[mechType])\n",
    "\n",
    "        numCoords = 8\n",
    "\n",
    "    if mechType in [8, 9, 10, 19, 22, 24]: # some types of 6 bar only have 7 joints\n",
    "        numCoords = 7\n",
    "\n",
    "    # Create directories if they do not exist\n",
    "    for d in [saveDir, saveDirNpy, saveDirWalking, saveDirWalkingPlot]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    for initState in tqdm(initStates[mechType*NUM_MECHS: (mechType+1)*NUM_MECHS, :numCoords*2]): # 5*2 for 4 bars, 8*2 for 6 bars\n",
    "        coord = np.round(initState, 3).reshape((numCoords,2))\n",
    "        dist = calc_dist(coord)\n",
    "\n",
    "        if max(dist) > 10:\n",
    "            continue\n",
    "\n",
    "        param = coord.tolist()\n",
    "\n",
    "        name = str(param).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\") \n",
    "\n",
    "        exampleData = {\n",
    "            'type': types[mechType], \n",
    "            'params': param,\n",
    "            'speedScale':speedscale, # 1 \n",
    "            'steps':steps, # 360 \n",
    "            'relativeTolerance':0.1 \n",
    "        }\n",
    "\n",
    "\n",
    "        batch.append(exampleData) #... You should use a function to decide save str. \n",
    "        batchSaveStr.append(saveDir + '/' + name )       # old method of doing things \n",
    "        batchSaveNpyStr.append(saveDirNpy + '/' + name ) # old method of doing things \n",
    "\n",
    "        if len(batch) >= batchCount:\n",
    "            try:\n",
    "                temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "                time.sleep(0.02)\n",
    "            except ValueError as v:\n",
    "                for i in range(3):\n",
    "                    time.sleep(2)\n",
    "                    try:\n",
    "                        temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "                        break\n",
    "                    except ValueError as v2:\n",
    "                        errCtr += 1\n",
    "            for i in range(len(temp)):\n",
    "                P = np.array(temp[i]['poses'])\n",
    "                try:\n",
    "                    if len(P.shape) >= 1:\n",
    "                        if P.shape[0] >= minsteps:\n",
    "                            # do normalization, also get the transformation parameters. \n",
    "                            # also the paras are saved instead of MP (M: tranformation matrix, P: points in the matrix)\n",
    "                            # This is just to avoid decimal difference problem \n",
    "                            imageMat, transParamSet, success = process_mech_051524(P, couplerCurveIndex[mechType])\n",
    "                            if success:\n",
    "\n",
    "                                # change Tstr if needed \n",
    "                            # normalized coords\n",
    "                                normalized_coords = normalize_data_122223(P[:,couplerCurveIndex[mechType],:], scaling=3.5)[0]\n",
    "                                #print(normalized_coords)\n",
    "                                \n",
    "                                '''plt.figure(figsize=(6, 6))\n",
    "                                plt.plot(normalized_coords[:, 0], normalized_coords[:, 1], marker='o')\n",
    "                                plt.title('Normalized Coupler Curve')\n",
    "                                plt.xlabel('X')\n",
    "                                plt.ylabel('Y')\n",
    "                                plt.axis('equal')\n",
    "                                plt.grid(True)\n",
    "                                plt.show()'''\n",
    "\n",
    "                                # Compute Fourier descriptors\n",
    "                                #fd = np.fft.fft(normalized_coords[:, 0] + 1j * normalized_coords[:, 1])\n",
    "                                #print(fd)\n",
    "\n",
    "                                # Inverse FFT to reconstruct curve\n",
    "                                #reconstructed = np.fft.ifft(fd)\n",
    "                                #reconstructed_coords = np.column_stack((reconstructed.real, reconstructed.imag))\n",
    "\n",
    "                                pca_output = detect_flat_via_pca(normalized_coords)\n",
    "\n",
    "                                sharp, kappa = has_sharp_edges(normalized_coords, curvature_threshold=150.0)\n",
    "\n",
    "                                self_intersecting = has_self_intersections(resample_uniform(normalized_coords, 512))\n",
    "                                \n",
    "                                #ground_clearance = ground_clearance_check(resample_uniform(P[:,couplerCurveIndex[mechType],:], 512), coord, pca_output['flat_indices'])\n",
    "                                # batchSaveStr[i].replace(saveDir, '').replace('/', '') is a string of numbers separated by spaces\n",
    "                                # Convert it to a list of coordinates (pairs)\n",
    "                                #print(\"coordinates: \" + batchSaveStr[i].replace(saveDir, '').replace('/', ''))\n",
    "                                joint_coords = np.array(str_to_coords(batchSaveStr[i].replace(saveDir, '').replace('/', '')))\n",
    "                                ground_clearance = ground_clearance_check(\n",
    "                                    resample_uniform(P[:,couplerCurveIndex[mechType],:], 512),\n",
    "                                    joint_coords,\n",
    "                                    pca_output['flat_indices']\n",
    "                                )\n",
    "                                # resample uniform uses the unnormalized coords for everything\n",
    "                                # P[:,couplerCurveIndex[mechType],:] is the coupler curve coords before normalization\n",
    "                                # this needs resampling because pca_output does resampling to 512 points\n",
    "\n",
    "                                # coord is the original joint coords in numPy array format\n",
    "                                # pca_output['flat_indices'] are the indices of the flat portion of the coupler curve\n",
    "                                if pca_output['is_flat_enough'] and is_closed(normalized_coords) and (not sharp) and (not self_intersecting):\n",
    "                                    #plot_flat_fit_with_joints(resample_uniform(P[:,couplerCurveIndex[mechType],:], 512), pca_output['flat_indices'], joint_coords)\n",
    "                                    #continue\n",
    "                                    #print(name)\n",
    "                                    pass\n",
    "                                    #print(\"\\033[95m\" + f\"flat but without ground clearance: \\n mechtype: {types[mechType]} \\n initla joints {param}, \\n flat fraction {pca_output['flat_fraction']:.2f}, \\nmax_run {pca_output['max_run']}, \\nN {pca_output['N']}, \\norientation {pca_output['orientation_deg']:.1f} deg, \\nsharp edges {sharp}, ground clearance {ground_clearance}\" + \"\\033[0m\")\n",
    "\n",
    "                                # if it satisfies everything and ground clearance, \n",
    "                                if pca_output['is_flat_enough'] and is_closed(normalized_coords) and (not sharp) and ground_clearance and (not self_intersecting):\n",
    "                                \n",
    "                                    #plot_flat_fit_with_joints(resample_uniform(P[:,couplerCurveIndex[mechType],:], 512), pca_output['flat_indices'], joint_coords)\n",
    "\n",
    "                                    print(\"\\033[92m\" + f\"flat but !!!!!WITH!!!!! ground clearance: \\n mechtype: {types[mechType]} \\n initla joints {param}, \\n flat fraction {pca_output['flat_fraction']:.2f}, \\nmax_run {pca_output['max_run']}, \\nN {pca_output['N']}, \\norientation {pca_output['orientation_deg']:.1f} deg, \\nsharp edges {sharp}, ground clearance {ground_clearance}\" + \"\\033[0m\")\n",
    "\n",
    "                                    #print(\"PCA Output:\", pca_output)\n",
    "\n",
    "                                    # change Tstr if needed \n",
    "                                    Tstr = np.array2string(np.round(transParamSet, 3), precision=3, suppress_small=True).replace(\"[\", \"\").replace(\"]\", \"\") # Wei asked for this part\n",
    "                                    Tstr = re.sub('\\s+', ' ', Tstr) # to replace multiple sequential spaces together\n",
    "                                    binary_data = np.uint8(imageMat[:,:,0]) * 255\n",
    "                                    img = Image.fromarray(binary_data)\n",
    "\n",
    "                                    img.save(saveDirWalking + \"/\" + name + ' ' + Tstr + '.jpg')\n",
    "                                    save_flat_fit_with_joints(resample_uniform(P[:,couplerCurveIndex[mechType],:], 512), pca_output['flat_indices'], joint_coords, saveDirWalkingPlot, str(name + ' ' + Tstr + '.jpg'))\n",
    "                                    print(\"img savbed to\" + saveDirWalking + \"/\" + name + ' ' + Tstr + '.jpg')\n",
    "                                    print(\"plot saved to\" + str(name + ' ' + Tstr + '.jpg'))\n",
    "                                    \n",
    "                                    #plot_flat_fit_with_joints(resample_uniform(P[:,couplerCurveIndex[mechType],:], 512), pca_output['flat_indices'], batchSaveStr[i])\n",
    "\n",
    "                                '''# Plot original and reconstructed curves\n",
    "                                plt.figure(figsize=(6, 6))\n",
    "                                plt.plot(normalized_coords[:, 0], normalized_coords[:, 1], label='Original', marker='o')\n",
    "                                plt.plot(reconstructed_coords[:, 0], reconstructed_coords[:, 1], label='Reconstructed', linestyle='--', marker='x')\n",
    "\n",
    "                                # Use only the first N low-frequency Fourier coefficients for smoothing\n",
    "                                N = 10  # You can adjust N for more/less smoothing\n",
    "\n",
    "                                fd_low = np.zeros_like(fd)\n",
    "                                fd_low[:N] = fd[:N]\n",
    "                                fd_low[-N+1:] = fd[-N+1:]\n",
    "\n",
    "                                smoothed = np.fft.ifft(fd_low)\n",
    "                                smoothed_coords = np.column_stack((smoothed.real, smoothed.imag))\n",
    "\n",
    "                                plt.plot(smoothed_coords[:, 0], smoothed_coords[:, 1], label=f'Smoothed (N={N})', color='red', linewidth=2)\n",
    "\n",
    "\n",
    "\n",
    "                                plt.title('Original vs Reconstructed Curve (FFT)')\n",
    "                                plt.xlabel('X')\n",
    "                                plt.ylabel('Y')\n",
    "                                plt.axis('equal')\n",
    "                                plt.grid(True)\n",
    "                                plt.legend()\n",
    "                                plt.show()\n",
    "\n",
    "                                print(compute_fd_features(normalized_coords))\n",
    "\n",
    "\n",
    "                                # change Tstr if needed \n",
    "                                Tstr = np.array2string(np.round(transParamSet, 3), precision=3, suppress_small=True).replace(\"[\", \"\").replace(\"]\", \"\") # Wei asked for this part\n",
    "                                Tstr = re.sub('\\s+', ' ', Tstr) # to replace multiple sequential spaces together\n",
    "                                binary_data = np.uint8(imageMat[:,:,0]) * 255\n",
    "                                img = Image.fromarray(binary_data)\n",
    "                                if needAddtional[mechType]: # need additional description (replace old method)\n",
    "                                    pinit = (np.array(temp[i]['posInit'])[:savePointNumber[mechType], :].flatten().tolist())\n",
    "                                    name = format_floats_to_string(pinit)\n",
    "                                    #img.save(saveDir + '/' + name + ' ' + types[mechType] + ' '  + Tstr + '.jpg')\n",
    "                                    # do not save all paths, only save walking\n",
    "                                else:                       # traditional if no added \n",
    "                                    #img.save(batchSaveStr[i] + ' ' + types[mechType] + ' ' + Tstr + '.jpg')\n",
    "\n",
    "                                if pca_output['is_flat_enough'] and is_closed(normalized_coords) and (not sharp):\n",
    "                                    print(\"\\033[94m\" + f\"found flat coupler curve: {batchSaveStr[i]} {types[mechType]} {Tstr}.jpg \\n type: {types[mechType]}\" + \"\\033[0m\")\n",
    "                                    print(coord)\n",
    "                                #plt.imshow(imageMat)\n",
    "                                #plt.savefig(batchSaveStr[i] + Tstr + '.jpg')\n",
    "                                #plt.clf()'''\n",
    "                            else: \n",
    "                                normFailCtr += 1\n",
    "                            pass                        \n",
    "                except ValueError as v:\n",
    "                    print(v)\n",
    "                except FileNotFoundError as f:\n",
    "                    print(f)\n",
    "            batch = []\n",
    "            batchSaveStr = []\n",
    "            batchSaveNpyStr = []\n",
    "\n",
    "    if len(batch) >= batchCount:\n",
    "        #print(batch[0], '\\n', batch[1])\n",
    "        #print(batchSaveStr[0], '\\n', batchSaveStr[1])\n",
    "        try:\n",
    "            temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "            time.sleep(0.02)\n",
    "        except ValueError as v:\n",
    "            for i in range(3):\n",
    "                time.sleep(2)\n",
    "                try:\n",
    "                    temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "                    break\n",
    "                except ValueError as v2:\n",
    "                        errCtr += 1\n",
    "        print(errCtr)\n",
    "        for i in range(len(temp)):\n",
    "            P = np.array(temp[i]['poses']) \n",
    "            try:\n",
    "                if len(P.shape) >= 1:\n",
    "                    if P.shape[0] >= minsteps:\n",
    "                        # do normalization, also get the transformation parameters. \n",
    "                        # also the paras are saved instead of MP (M: tranformation matrix, P: points in the matrix)\n",
    "                        # This is just to avoid decimal difference problem \n",
    "                        imageMat, transParamSet, success = process_mech_051524(P, couplerCurveIndex[mechType])\n",
    "                        if success:\n",
    "                            Tstr = np.array2string(np.round(transParamSet, 3), precision=3, suppress_small=True).replace(\"[\", \"\").replace(\"]\", \"\") # Wei asked for this part\n",
    "                            Tstr = re.sub('\\s+', ' ', Tstr) # to replace multiple sequential spaces together\n",
    "                            binary_data = np.uint8(imageMat[:,:,0]) * 255\n",
    "                            img = Image.fromarray(binary_data)\n",
    "                            if needAddtional[mechType]: # need additional description (replace old method)\n",
    "                                pinit = (np.array(temp[i]['posInit'])[:savePointNumber[mechType], :].flatten().tolist())\n",
    "                                name = format_floats_to_string(pinit)\n",
    "                                #img.save(saveDir + '/' + name + ' ' + types[mechType] + ' '  + Tstr + '.jpg')\n",
    "                            else:                       # traditional if no added \n",
    "                                #img.save(batchSaveStr[i] + ' ' + types[mechType] + ' '  + Tstr + '.jpg') \n",
    "                                continue\n",
    "\n",
    "                            if pca_output['is_flat_enough'] and is_closed(normalized_coords) and (not sharp):\n",
    "                                print(\"\\033[94m\" + f\"found flat coupler curve: {batchSaveStr[i]} {types[mechType]} {Tstr}.jpg \\n type: {types[mechType]}\" + \"\\033[0m\")\n",
    "                            #plt.imshow(imageMat)\n",
    "                            #plt.savefig(batchSaveStr[i] + Tstr + '.jpg')\n",
    "                            #plt.clf()\n",
    "                        else:\n",
    "                            normFailCtr += 1\n",
    "                            pass       \n",
    "            except ValueError as v:\n",
    "                print(v)\n",
    "            except FileNotFoundError as f:\n",
    "                print(f)\n",
    "        batch = []\n",
    "        batchSaveStr = []\n",
    "        batchSaveNpyStr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(360, 8, 2)\n"
     ]
    }
   ],
   "source": [
    "print(normFailCtr) # basically not too many steps is the reason. \n",
    "print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Jupyter] *",
   "language": "python",
   "name": "conda-env-Jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
