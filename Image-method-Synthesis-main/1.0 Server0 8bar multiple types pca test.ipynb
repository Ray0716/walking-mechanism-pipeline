{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['811', '812', '813', '814', '815', '816', '817', '818', '819', '821', '822', '823', '824', '825', '831', '832']\n",
      "['Type811-', 'Type812-', 'Type813-', 'Type814-', 'Type815-', 'Type816-', 'Type817-', 'Type818-', 'Type819-', 'Type821-', 'Type822-', 'Type823-', 'Type824-', 'Type825-', 'Type831-', 'Type832-']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "from glob import glob\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from itertools import islice\n",
    "from PIL import Image\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from path_decomposition import linkMajor, computeSolSteps, linkMajor2B\n",
    "\n",
    "\n",
    "# Headless simulator version\n",
    "index = 0 # local server index \n",
    "API_ENDPOINT = 'http://localhost:4001/simulation-8bar' # NOT THE LS VERSION\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "batchCount = 1 # Send this number of samples to MotionGen each time \n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)\n",
    "\n",
    "mechType = 3\n",
    "\n",
    "topo_numbers = []\n",
    "with open('8bar.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('Topo '):\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2 and parts[1].isdigit() and len(parts[1]) == 3:\n",
    "                topo_numbers.append(parts[1])\n",
    "print(topo_numbers)\n",
    "# ['811', '812', '813', '814', '815', '816', '817', '818', '819', '821', '822', '823', '824', '825', '831', '832']\n",
    "\n",
    "typesList = [f\"Type{num}-\" for num in topo_numbers]\n",
    "print(typesList)\n",
    "#  0            1           2            3          4            5          6          7             8           9           10           11         12          13           14         15 \n",
    "# ['Type811-', 'Type812-', 'Type813-', 'Type814-', 'Type815-', 'Type816-', 'Type817-', 'Type818-', 'Type819-', 'Type821-', 'Type822-', 'Type823-', 'Type824-', 'Type825-', 'Type831-', 'Type832-']\n",
    "\n",
    "# shape of init pos \n",
    "types   = [typesList[mechType]]\n",
    "initPos = [22] #11 pts, 22 coords\n",
    "randSeed= [44] #ignore\n",
    "couplerCurveIndices = [10]\n",
    "distLens = [55] #ignore\n",
    "\n",
    "output_dir = \"outputs-8bar\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for t in typesList:\n",
    "    dir_path = os.path.join(output_dir, t + \"0\")\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good old ones \n",
    "\n",
    "def isValid(seq):\n",
    "    if len(seq.shape) == 2:\n",
    "        isVal = np.var(seq[:,0]) <= 5e-3 and np.var(seq[:,1]) <= 5e-3\n",
    "    else:\n",
    "        isVal = len(seq) == 0 or np.var(seq) <= 5e-3\n",
    "\n",
    "    if isVal:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def center_data(X):\n",
    "    \"\"\" Center the data by subtracting the mean of each column.\n",
    "        Return the translated X and the translation matrix \n",
    "    \"\"\"\n",
    "    m = np.mean(X, axis=0) # (n, 2)\n",
    "    return X - m, np.matrix([[1, 0, -m[0]], [0, 1, -m[1]], [0, 0, 1]]) # equal to XP this is a translation matrix tranposed  \n",
    "\n",
    "\n",
    "def scale_data(X, scaling = 0): \n",
    "    \"\"\" Scale the data according to two different metrics \n",
    "        If scaling == 0 (default), scaling method is normalization (average distance 1)\n",
    "        If otherwise, scaling method is standardization to a certain scale \n",
    "        Return the scaled X, and the scaling matrix. \n",
    "    \"\"\"\n",
    "    if scaling == 0:\n",
    "        # use variance. \n",
    "        denom = np.sqrt(np.var(X[:,0]) + np.var(X[:,1]))\n",
    "        scaled_curve = X /denom\n",
    "        ScaleMat = np.matrix([[1/denom, 0, 0], [0, 1/denom, 0], [0, 0, 1]])\n",
    "    else:\n",
    "        # Compute the maximum distance from the origin \n",
    "        max_distance = np.max(np.linalg.norm(X, axis=1))\n",
    "        scaled_curve = X * scaling / max_distance\n",
    "        ScaleMat = np.matrix([[scaling/max_distance, 0, 0], [0, scaling/max_distance, 0], [0, 0, 1]])\n",
    "    return scaled_curve, ScaleMat\n",
    "\n",
    "\n",
    "def rotate_data(X, tol = 1e-4, randinit = False): \n",
    "    \"\"\" Performs the PCA and determines rotation angle phi \n",
    "        More precisely it is snapping the greatest principal axis to the X-axis. \n",
    "        Return the rotated X and the rotation matrix \n",
    "    \"\"\"\n",
    "    # Ensure input is numpy array\n",
    "    X = np.array(X)\n",
    "    \n",
    "    phiInit = 0\n",
    "    if randinit:\n",
    "        phiInit = np.random.rand() * math.pi * 2 \n",
    "\n",
    "    rotationMatInit = np.matrix([\n",
    "        [np.cos(phiInit), -np.sin(phiInit), 0], \n",
    "        [np.sin(phiInit), np.cos(phiInit), 0],\n",
    "        [0, 0, 1] \n",
    "    ])\n",
    "\n",
    "    X0 = rotate_curve(X, phiInit)\n",
    "    \n",
    "    # CRITICAL FIX: Ensure X0 is a numpy array, not a tuple\n",
    "    X0 = np.array(X0)\n",
    "    \n",
    "    # Now these operations will work properly\n",
    "    cx = np.mean(X0[:,0])\n",
    "    cy = np.mean(X0[:,1])\n",
    "    covar_xx = np.sum((X0[:,0] - cx)*(X0[:,0] - cx))/X0.shape[0]\n",
    "    covar_xy = np.sum((X0[:,0] - cx)*(X0[:,1] - cy))/X0.shape[0]\n",
    "    covar_yx = np.sum((X0[:,1] - cy)*(X0[:,0] - cx))/X0.shape[0]\n",
    "    covar_yy = np.sum((X0[:,1] - cy)*(X0[:,1] - cy))/X0.shape[0]\n",
    "    covar = np.array([[covar_xx, covar_xy],[covar_yx, covar_yy]])\n",
    "\n",
    "    if np.abs(np.linalg.det(covar)) < tol:\n",
    "        phi = 0 # why rotate anyway? \n",
    "    else:\n",
    "        eig_val, eig_vec= np.linalg.eig(covar) \n",
    "        # Inclination of major principal axis w.r.t. x axis\n",
    "        # Enforcing the cross-product of the two eigenvectors to be greater than 0. \n",
    "        # Not necessary, but it looks clean to do so. \n",
    "        # Eigenvector matrix: [a, b], det = crossproduct of b x a\n",
    "        if np.linalg.det(eig_vec) > 0:\n",
    "            eig_vec[0,:] = -eig_vec[0,:] # enforcing a x b > 0 \n",
    "        if eig_val[0] > eig_val[1]:\n",
    "            phi= np.arctan2(eig_vec[1,0], eig_vec[0,0])\n",
    "        else:\n",
    "            phi= np.arctan2(eig_vec[1,1], eig_vec[0,1])\n",
    "    \n",
    "    rotated_curve = rotate_curve(X0, phi)\n",
    "    \n",
    "    # Ensure the final output is also a numpy array\n",
    "    rotated_curve = np.array(rotated_curve)\n",
    "    \n",
    "    rotationMat = np.matrix([\n",
    "        [np.cos(phi), -np.sin(phi), 0], \n",
    "        [np.sin(phi), np.cos(phi), 0],\n",
    "        [0, 0, 1] \n",
    "    ])\n",
    "\n",
    "    return rotated_curve, np.matmul(rotationMat, rotationMatInit)\n",
    "\n",
    "\n",
    "def reflect_data(X):\n",
    "    \"\"\" Computes the third order moment and determines the reflections \n",
    "        The data must be rotated before this step. \n",
    "\n",
    "    \"\"\"\n",
    "    # Reflection normalization \n",
    "    x_scaled = X[:, 0]\n",
    "    y_scaled = X[:, 1]\n",
    "\n",
    "    # see paper Geometric Invariant Curve and Surface Normalization\n",
    "    # compute the 3rd-order moments \n",
    "    m12 = np.sum((x_scaled**1)*(y_scaled**2))\n",
    "    m21 = np.sum((x_scaled**2)*(y_scaled**1))\n",
    "    signm12 = np.sign(m12)\n",
    "    signm21 = np.sign(m21)\n",
    "    if np.abs(signm12) < 1e-5:\n",
    "        signm12 = 1\n",
    "    if np.abs(signm21) < 1e-5:\n",
    "        signm21 = 1\n",
    "\n",
    "    reflectionMat = np.array(\n",
    "        [[signm12, 0],\n",
    "         [0, signm21]]\n",
    "    ) \n",
    "\n",
    "    if np.abs(m12) > np.abs(m21):\n",
    "        reflectionMat = np.matmul(np.array([[0,1],[1,0]]), reflectionMat)\n",
    "\n",
    "    reflected_Curve = np.matmul(reflectionMat, np.array(X).T).T\n",
    "    reflectionMat = np.matrix(\n",
    "        [[reflectionMat[0,0], reflectionMat[0,1], 0], \n",
    "         [reflectionMat[1,0], reflectionMat[1,1], 0], \n",
    "         [0, 0, 1]\n",
    "        ]\n",
    "    ) \n",
    "\n",
    "    return reflected_Curve, reflectionMat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_pca_inclination(qx, qy, ax=None, label=''):\n",
    "    \"\"\" Performs the PCA\n",
    "        Return transformation matrix\n",
    "    \"\"\"\n",
    "    cx = np.mean(qx)\n",
    "    cy = np.mean(qy)\n",
    "    covar_xx = np.sum((qx - cx)*(qx - cx))/len(qx)\n",
    "    covar_xy = np.sum((qx - cx)*(qy - cy))/len(qx)\n",
    "    covar_yx = np.sum((qy - cy)*(qx - cx))/len(qx)\n",
    "    covar_yy = np.sum((qy - cy)*(qy - cy))/len(qx)\n",
    "    covar = np.array([[covar_xx, covar_xy],[covar_yx, covar_yy]])\n",
    "    eig_val, eig_vec= np.linalg.eig(covar)\n",
    "\n",
    "    # Inclination of major principal axis w.r.t. x axis\n",
    "    if eig_val[0] > eig_val[1]:\n",
    "        phi= np.arctan2(eig_vec[1,0], eig_vec[0,0])\n",
    "    else:\n",
    "        phi= np.arctan2(eig_vec[1,1], eig_vec[0,1])\n",
    "\n",
    "    return phi\n",
    "\n",
    "\n",
    "def get_normalize_curve(jd, steps=None, rotations=1, normalize=True, transformParas=None):\n",
    "    jd = np.array(jd)\n",
    "    joint_data_n, x_mean, y_mean, denom, phi = [], None, None, None, None\n",
    "    if isValid(jd):\n",
    "        if steps:\n",
    "            sample_indices = np.linspace(0, jd.shape[0]-1, steps, dtype=np.int32)\n",
    "            jd = jd[sample_indices,:]\n",
    "        if normalize:\n",
    "            if not transformParas:\n",
    "                x_mean = np.mean(jd[:,0], axis=0, keepdims=True)\n",
    "                y_mean = np.mean(jd[:,1], axis=0, keepdims=True)\n",
    "            else:\n",
    "                x_mean, y_mean, denom, phi = transformParas\n",
    "            jd[:,0] = jd[:,0] - x_mean\n",
    "            jd[:,1] = jd[:,1] - y_mean\n",
    "\n",
    "            if not transformParas:\n",
    "                denom = np.sqrt(np.var(jd[:,0], axis=0, keepdims=True) + np.var(jd[:,1], axis=0, keepdims=True))\n",
    "                denom = np.expand_dims(denom, axis=1)\n",
    "            jd = jd / denom\n",
    "            t = 0\n",
    "        if not transformParas:\n",
    "            phi = -get_pca_inclination(jd[:,0], jd[:,1])\n",
    "        jd[:,0], jd[:, 1] = rotate_curve(jd, phi)\n",
    "        for tt in range(rotations):\n",
    "            joint_data_n.append(jd.copy())\n",
    "            if rotations > 1:\n",
    "                jd[:,0], jd[:,1] = rotate_curve(jd, t)\n",
    "                t = 2*np.pi/rotations\n",
    "\n",
    "    return joint_data_n, x_mean, y_mean, denom, phi\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def rotate_curve(cur, theta):\n",
    "    cpx = cur[:,0]*np.cos(theta) - cur[:,1]*np.sin(theta)\n",
    "    cpy = cur[:,0]*np.sin(theta) + cur[:,1]*np.cos(theta)\n",
    "    return cpx, cpy\n",
    "\n",
    "\n",
    "def digitize_seq(nums, minlim, maxlim, bin_size=64):\n",
    "    bins = np.linspace(minlim, maxlim, bin_size-1)\n",
    "    nums_indices = np.digitize(nums, bins)\n",
    "    return nums_indices\n",
    "\n",
    "\n",
    "def get_normalize_joint_data_wrt_one_curve(joint_data, ref_ind = 4):\n",
    "    ''' input s = [num_curves, num_points, 2]\n",
    "    '''\n",
    "    joint_data_n = []\n",
    "    s = np.array(joint_data)\n",
    "\n",
    "    if isValid(s[ref_ind]):\n",
    "        x_mean = np.mean(s[ref_ind:ref_ind+1,:,0], axis=1, keepdims=True)\n",
    "        y_mean = np.mean(s[ref_ind:ref_ind+1,:,1], axis=1, keepdims=True)\n",
    "        s[:,:,0] = s[:,:,0] - x_mean\n",
    "        s[:,:,1] = s[:,:,1] - y_mean\n",
    "        denom = np.sqrt(np.var(s[ref_ind:ref_ind+1,:,0], axis=1, keepdims=True) + np.var(s[ref_ind:ref_ind+1,:,1], axis=1, keepdims=True))\n",
    "        denom = np.expand_dims(denom, axis=2) #is this scale? \n",
    "        s = s / denom\n",
    "        phi = -get_pca_inclination(s[ref_ind:ref_ind+1,:,0], s[ref_ind:ref_ind+1,:,1])\n",
    "        for i in range(s.shape[0]):\n",
    "            s[i,:,0], s[i,:,1] = rotate_curve(s[i], phi)\n",
    "    else:\n",
    "        return s, [None, None, None, None], False\n",
    "\n",
    "    # s has a shape of (j_num, state, dim)\n",
    "    return s, [x_mean[0][0], y_mean[0][0], denom[0][0][0], phi], True # tx, ty, scaling, rotation angle \n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# There are some other necessary transformations. (x_mean, y_mean, phi, denom) are from get_normalize_curve. \n",
    "##############################################################################################\n",
    "def get_image_from_point_cloud(points, xylim, im_size, inverted = True, label=None):\n",
    "    mat = np.zeros((im_size, im_size, 1), dtype=np.uint8)\n",
    "    x = digitize_seq(points[:,0], -xylim, xylim, im_size)\n",
    "    if inverted:\n",
    "        y = digitize_seq(points[:,1]*-1, -xylim, xylim, im_size)\n",
    "        mat[y, x, 0] = 1\n",
    "    else:\n",
    "        y = digitize_seq(points[:,1], -xylim, xylim, im_size)\n",
    "        mat[x, y, 0] = 1\n",
    "    return mat\n",
    "\n",
    "\n",
    "def process_mech_102723(jointData, ref_ind, im_size = 64, xylim = 3.5, inverted = True, swapAxes = True):\n",
    "    paras = None\n",
    "\n",
    "    # It is possible the jointData format is (angles, joint, (x, y)). \n",
    "    # You should put a True if this happens. (This is how files are saved).\n",
    "    # I literally don't understand why I saved jointData with a shape of (angles, joint, (x, y)) \n",
    "    if swapAxes:\n",
    "        jointData = np.swapaxes(jointData, 0, 1)\n",
    "\n",
    "    # This converts all \n",
    "    jointData, paras, success = get_normalize_joint_data_wrt_one_curve(jointData, ref_ind= ref_ind)\n",
    "\n",
    "    # jointData format from now on becomes np.array with a shape of (joint, curve_length, dimension)\n",
    "    jointData = np.array(jointData)\n",
    "\n",
    "    if success:\n",
    "        # get binaryImage \n",
    "        jd = jointData[ref_ind]\n",
    "        mat = get_image_from_point_cloud(jd, xylim=xylim, im_size=im_size, inverted=inverted)\n",
    "        return mat, paras, success\n",
    "    else: \n",
    "        return None, None, success\n",
    "\n",
    "def calc_dist(coord):\n",
    "    # Calculate differences using broadcasting\n",
    "    diffs = coord[:, np.newaxis, :] - coord[np.newaxis, :, :]\n",
    "    squared_dists = np.sum(diffs ** 2, axis=2)\n",
    "\n",
    "    # Extract the upper triangle indices where i < j\n",
    "    i, j = np.triu_indices(len(coord), k=1)\n",
    "    dist_arr = np.sqrt(squared_dists[i, j])\n",
    "    dist_arr = dist_arr/min(dist_arr)\n",
    "    return np.round(dist_arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B2T(Bextend):\n",
    "    n = len(Bextend[0])\n",
    "    Textend = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        if Bextend[0][i]:\n",
    "            Textend[i][i] = 1\n",
    "\n",
    "    for B in Bextend:\n",
    "        for i in range(n):\n",
    "            for j in range(i+1,n):\n",
    "                if B[i] and B[j]:\n",
    "                    Textend[i][j] = 1\n",
    "                    Textend[j][i] = 1\n",
    "    return Textend.astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]]\n",
      "[0, 0, 7, 2, 2, 2, 5, 5]\n",
      "[0, 2, 9, 1, 3, 5, 9, 4]\n",
      "[2, 0, 8, 3, 1, 3, 6, 6]\n",
      "[1, [3, 4], [4, 6], 0, [2, 4], [7, 8], 8, [2, 3]]\n",
      "[7, 7, 0, 7, 7, 7, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import copy \n",
    "\n",
    "def exchange_rows(i, j, cp, mat):\n",
    "    mat_copy = copy.deepcopy(mat)\n",
    "    mat_copy[cp][-1] = 1\n",
    "    mat_copy[i], mat_copy[j] = mat_copy[j], mat_copy[i]\n",
    "    return mat_copy\n",
    "\n",
    "def exchange_columns(i, j, mat, pos):\n",
    "    mat_copy = copy.deepcopy(mat)\n",
    "    if pos[i] == j:\n",
    "        return mat_copy, pos\n",
    "    if pos[j] != j:\n",
    "        j = pos.index(j)\n",
    "    for row_i in range(len(mat_copy)):\n",
    "        mat_copy[row_i][i], mat_copy[row_i][j] = mat_copy[row_i][j], mat_copy[row_i][i]\n",
    "    \n",
    "    pos[i], pos[j] = pos[j], pos[i]\n",
    "    return mat_copy, pos\n",
    "\n",
    "#--- replace below code with info from 8bar.txt corresponding to the 8 bar mech type\n",
    "# Read 8bar.txt and extract the section for the current mechanism\n",
    "\n",
    "# Use the current type string for the mechanism (e.g., 'Type811')\n",
    "mech_number = typesList[index].replace('Type', '').replace('-', '')\n",
    "mech_name = f\"Topo {mech_number}\"\n",
    "section_found = False\n",
    "section_lines = []\n",
    "\n",
    "with open('8bar.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip().startswith('Topo') and mech_name in line:\n",
    "            section_found = True\n",
    "            continue\n",
    "        if section_found:\n",
    "            if line.strip().startswith('Topo') and mech_name not in line:\n",
    "                break  # End of current section\n",
    "            if line.strip() and not line.strip().startswith('Topo'):\n",
    "                section_lines.append(line)\n",
    "\n",
    "if not section_lines:\n",
    "    raise ValueError(f\"Section for {mech_name} not found or empty in 8bar.txt.\")\n",
    "\n",
    "# Prepare a local namespace to exec the lines\n",
    "local_vars = {}\n",
    "exec(''.join(section_lines), {}, local_vars)\n",
    "\n",
    "# Assign the extracted variables, with error handling\n",
    "try:\n",
    "    B = local_vars['B']\n",
    "    grounds = local_vars['grounds']\n",
    "    actuator = local_vars['actuator']\n",
    "    actuator_fixed = local_vars['actuator_fixed']\n",
    "    chain = local_vars['chain']\n",
    "    coupler_point = local_vars['coupler_point']\n",
    "except KeyError as e:\n",
    "    raise KeyError(f\"Variable {e} not found in section for {mech_name} in 8bar.txt. Check the file format.\")\n",
    "\n",
    "\n",
    "'''B = [[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]]\n",
    "\n",
    "\n",
    "grounds = [0, 0, 1, 1, 5, 5, 6, 6, 2, 2, 2, 4, 4, 3, 3, 3]\n",
    "actuator = [0, 2, 0, 1, 6, 7, 5, 4, 1, 3, 4, 6, 5, 2, 7, 3]\n",
    "actuator_fixed = [2, 0, 1, 0, 7, 6, 4, 5, 3, 4, 1, 5, 6, 7, 3, 2]\n",
    "chain = [1, [3, 7, 8], 2, [3, 4], [5, 9], [2, 3, 8], [6, 9], [1, 3], 0, [2, 7, 8], 5, 7, 4, 0, 6, [1, 4]]\n",
    "coupler_point = [7, 6, 6, 7, 0, 1, 0, 7, 7, 7, 7, 0, 0, 6, 1, 6]'''\n",
    "\n",
    "print(B)\n",
    "print(grounds)\n",
    "print(actuator)\n",
    "print(actuator_fixed)\n",
    "print(chain)\n",
    "print(coupler_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mechanism type: Type811-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:48<00:00, 104.08it/s]\n",
      "100%|██████████| 5000/5000 [00:45<00:00, 108.92it/s]\n",
      "100%|██████████| 5000/5000 [00:51<00:00, 96.60it/s] \n",
      "100%|██████████| 5000/5000 [00:53<00:00, 94.17it/s] \n",
      "100%|██████████| 5000/5000 [00:46<00:00, 108.29it/s]\n",
      "100%|██████████| 5000/5000 [00:46<00:00, 106.83it/s]\n",
      "100%|██████████| 5000/5000 [00:54<00:00, 92.32it/s] \n",
      "100%|██████████| 5000/5000 [00:50<00:00, 99.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mechanism type: Type812-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:48<00:00, 103.25it/s]\n",
      "100%|██████████| 5000/5000 [00:46<00:00, 106.88it/s]\n",
      "100%|██████████| 5000/5000 [00:50<00:00, 98.31it/s] \n",
      "100%|██████████| 5000/5000 [00:51<00:00, 96.53it/s] \n",
      "100%|██████████| 5000/5000 [00:47<00:00, 106.32it/s]\n",
      "100%|██████████| 5000/5000 [00:45<00:00, 109.48it/s]\n",
      "100%|██████████| 5000/5000 [00:53<00:00, 93.34it/s] \n",
      "100%|██████████| 5000/5000 [00:50<00:00, 99.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mechanism type: Type813-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:46<00:00, 106.56it/s]\n",
      "100%|██████████| 5000/5000 [00:47<00:00, 104.47it/s]\n",
      "100%|██████████| 5000/5000 [00:56<00:00, 88.58it/s] \n",
      " 14%|█▎        | 685/5000 [00:06<00:43, 98.16it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 295\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    294\u001b[39m     temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     time.sleep(\u001b[32m0.02\u001b[39m)\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m v:\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "#initStates = np.load(\"./npy-inputs/\" + types[index] + '.npy')\n",
    "initStates = np.load(\"/gpfs/scratch/raytang/walking-dataset-generator-old-simulator/Image-method-Synthesis-main/npy-inputs/RandPos-.npy\")\n",
    "\n",
    "NUM_MECHS = 5000\n",
    "\n",
    "def is_curve_closed(coords, tolerance=0.1):\n",
    "    \"\"\"\n",
    "    Check if a curve is closed by comparing the distance between first and last points.\n",
    "    \n",
    "    Parameters:\n",
    "    - coords: numpy array of shape (N, 2) containing the curve points\n",
    "    - tolerance: maximum distance between first and last points to consider as closed\n",
    "    \n",
    "    Returns:\n",
    "    - Boolean: True if curve is closed, False otherwise\n",
    "    \"\"\"\n",
    "    if len(coords) < 3:\n",
    "        return False\n",
    "    \n",
    "    start_point = coords[0]\n",
    "    end_point = coords[-1]\n",
    "    distance = np.linalg.norm(end_point - start_point)\n",
    "    \n",
    "    return distance <= tolerance\n",
    "\n",
    "\n",
    "def normalize_data_122223(X, scaling = 0, tol = 1e-8, maxiter = 2):\n",
    "    X1, M1 = center_data(X) \n",
    "    X1, M2 = scale_data(X1, scaling = scaling)\n",
    "    X1, M3 = rotate_data(X1)\n",
    "    X1, M4 = reflect_data(X1)\n",
    "    M = M4*M3*M2*M1 # This is the transformation matrix \n",
    "\n",
    "    detVal = np.abs(np.linalg.det(M))\n",
    "    if detVal*scaling < tol:\n",
    "        for i in range(maxiter):\n",
    "            X1, M1 = center_data(X1)\n",
    "            X1, M2 = scale_data(X1, scaling = scaling)\n",
    "            X1, M3 = rotate_data(X1, randinit= True)\n",
    "            X1, M4 = reflect_data(X1)\n",
    "            if np.abs(np.linalg.det(M)) > tol or detVal*10 < np.abs(np.linalg.det(M)):\n",
    "                break\n",
    "    return X1, M4*M3*M2*M1, np.abs(np.linalg.det(M)) > tol\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "def has_sharp_edges(coords, curvature_threshold=15.0, smoothing_sigma=1.0):\n",
    "    if smoothing_sigma > 0:\n",
    "        x = gaussian_filter1d(coords[:,0], sigma=smoothing_sigma)\n",
    "        y = gaussian_filter1d(coords[:,1], sigma=smoothing_sigma)\n",
    "    else:\n",
    "        x = coords[:,0]\n",
    "        y = coords[:,1]\n",
    "\n",
    "    dx = np.gradient(x)\n",
    "    dy = np.gradient(y)\n",
    "    ddx = np.gradient(dx)\n",
    "    ddy = np.gradient(dy)\n",
    "\n",
    "    curvature = np.abs(dx * ddy - dy * ddx) / (dx**2 + dy**2)**1.5\n",
    "    return np.any(curvature > curvature_threshold), curvature\n",
    "\n",
    "def resample_uniform(points, M):\n",
    "    dif = np.diff(points, axis=0)\n",
    "    seglen = np.sqrt((dif**2).sum(axis=1))\n",
    "    s = np.concatenate(([0], np.cumsum(seglen)))\n",
    "    total = s[-1]\n",
    "    if total == 0:\n",
    "        return np.repeat(points[:1], M, axis=0)\n",
    "    s_uniform = np.linspace(0, total, M)\n",
    "    x = np.interp(s_uniform, s, points[:,0])\n",
    "    y = np.interp(s_uniform, s, points[:,1])\n",
    "    return np.column_stack((x, y))\n",
    "\n",
    "def pca_align(points):\n",
    "    pts = points - np.mean(points, axis=0)\n",
    "    U, S, VT = np.linalg.svd(pts, full_matrices=False)\n",
    "    pcs = VT.T\n",
    "    rotated = pts @ pcs\n",
    "    return rotated, pcs\n",
    "\n",
    "def detect_flat_via_pca(points, K_keep=12, N_resample=512, eps_slope=0.0075, min_fraction=1/4):\n",
    "    pts = resample_uniform(points, N_resample)\n",
    "    rotated, pcs = pca_align(pts)\n",
    "    dy = np.gradient(rotated[:,1])\n",
    "    flat_mask = np.abs(dy) < eps_slope\n",
    "    \n",
    "    from itertools import groupby\n",
    "    runs = [sum(1 for _ in g) for val,g in groupby(flat_mask) if val]\n",
    "    max_run = max(runs) if runs else 0\n",
    "    flat_fraction = max_run / len(flat_mask)\n",
    "    is_flat_enough = flat_fraction >= min_fraction\n",
    "    \n",
    "    first_pc = pcs[:,0]\n",
    "    angle = np.arctan2(first_pc[1], first_pc[0])\n",
    "\n",
    "    max_run = 0\n",
    "    run_indices = []\n",
    "    current_run = []\n",
    "\n",
    "    for i, is_flat in enumerate(flat_mask):\n",
    "        if is_flat:\n",
    "            current_run.append(i)\n",
    "            if len(current_run) > max_run:\n",
    "                max_run = len(current_run)\n",
    "                run_indices = current_run.copy()\n",
    "        else:\n",
    "            current_run = []\n",
    "\n",
    "    return {\n",
    "        'flat_fraction': float(flat_fraction),\n",
    "        'is_flat_enough': bool(is_flat_enough),\n",
    "        'orientation_rad': float(angle),\n",
    "        'orientation_deg': float(np.degrees(angle)),\n",
    "        'max_run': int(max_run),\n",
    "        'N': int(len(flat_mask)),\n",
    "        'flat_indices': np.array(run_indices, dtype=int), \n",
    "        'pts': pts,\n",
    "    }\n",
    "\n",
    "def ground_clearance_check(path_coords, joint_coords, flat_indices):\n",
    "    if len(flat_indices) == 0:\n",
    "        return False\n",
    "    flat_pts = path_coords[flat_indices]\n",
    "    m, b = np.polyfit(flat_pts[:,0], flat_pts[:,1], 1)\n",
    "\n",
    "    d_path = path_coords[:,1] - (m*path_coords[:,0] + b)\n",
    "    majority_sign = np.sign(np.sum(d_path))\n",
    "    if majority_sign == 0:\n",
    "        majority_sign = 1\n",
    "\n",
    "    d_joints = joint_coords[:,1] - (m*joint_coords[:,0] + b)\n",
    "    all_clear = np.all(np.sign(d_joints) == majority_sign)\n",
    "    return all_clear\n",
    "\n",
    "def save_flat_fit_with_joints(path_coords, flat_indices, joint_coords, save_dir, filename):\n",
    "    if len(flat_indices) == 0:\n",
    "        return\n",
    "    \n",
    "    flat_pts = path_coords[flat_indices]\n",
    "    m, b = np.polyfit(flat_pts[:,0], flat_pts[:,1], 1)\n",
    "    x_line = np.linspace(path_coords[:,0].min(), path_coords[:,0].max(), 200)\n",
    "    y_line = m * x_line + b\n",
    "\n",
    "    d_path = path_coords[:,1] - (m*path_coords[:,0] + b)\n",
    "    majority_sign = np.sign(np.sum(d_path))\n",
    "    if majority_sign == 0:\n",
    "        majority_sign = 1\n",
    "\n",
    "    d_joints = joint_coords[:,1] - (m*joint_coords[:,0] + b)\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.plot(path_coords[:,0], path_coords[:,1], 'b-', label='Full curve')\n",
    "    plt.plot(flat_pts[:,0], flat_pts[:,1], 'ro', label='Flat segment')\n",
    "    plt.plot(x_line, y_line, 'k--', label='Best fit line (flat)')\n",
    "\n",
    "    for i, (x, y) in enumerate(joint_coords):\n",
    "        if np.sign(d_joints[i]) == majority_sign:\n",
    "            plt.scatter(x, y, c='g', marker='x', s=80)\n",
    "        else:\n",
    "            plt.scatter(x, y, c='r', marker='x', s=80)\n",
    "        plt.text(x, y, str(i), fontsize=9, ha='right', va='bottom')\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.title(f\"coords:{filename}\")\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = f\"{filename}.jpg\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    plt.savefig(filepath, format='jpg')\n",
    "    plt.close()\n",
    "\n",
    "def has_self_intersections(coords):\n",
    "    line = LineString(coords)\n",
    "    return not line.is_simple\n",
    "\n",
    "def is_closed(pts):\n",
    "    start_pt = pts[0]\n",
    "    end_pt = pts[-1]\n",
    "    path_dist = np.linalg.norm(end_pt - start_pt)\n",
    "    is_closed = path_dist < 0.1\n",
    "    return is_closed\n",
    "\n",
    "def str_to_coords(s):\n",
    "    s = str(s)\n",
    "    nums = [float(x) for x in s.strip().split()]\n",
    "    return [[nums[j], nums[j+1]] for j in range(0, len(nums), 2)]\n",
    "\n",
    "# Worker function for parallel processing\n",
    "for index in range(0, 16):\n",
    "    mechType = index\n",
    "    types   = [typesList[mechType]]\n",
    "    print(f\"Processing mechanism type: {typesList[mechType]}\")\n",
    "    \n",
    "    couplerCurveIndex = 10\n",
    "    errCtr = 0\n",
    "    mechType = typesList[index]\n",
    "    batch = []\n",
    "    batchSaveStr = []\n",
    "    batchSaveNpyStr = []\n",
    "    \n",
    "    for i, (g, a, af, c, cp) in enumerate(zip(grounds, actuator, actuator_fixed, chain, coupler_point)):\n",
    "            \n",
    "        B_new = exchange_rows(0, g, cp, B)\n",
    "        col_positions = list(range(len(B[0])))\n",
    "        \n",
    "        B_new0, col_positions0 = exchange_columns(0, a, B_new, col_positions)\n",
    "        B_new1, col_positions1 = exchange_columns(2, af, B_new0, col_positions0)\n",
    "        B_new2, solSteps, c_final = None, None, None\n",
    "        \n",
    "        if type(c) == list:\n",
    "            isOptim = False\n",
    "            for ci in c:\n",
    "                B_new2, rand = exchange_columns(1, ci, B_new1, col_positions1)\n",
    "    \n",
    "                _, solSteps, _ = computeSolSteps(linkMajor(B_new2))\n",
    "                for solst in solSteps:\n",
    "                    if solst[1] == 'optim':\n",
    "                        isOptim = True\n",
    "                        break\n",
    "                c_final = ci\n",
    "                if not isOptim:\n",
    "                    break\n",
    "                        \n",
    "        else:\n",
    "            B_new2, rand = exchange_columns(1, c, B_new1, col_positions1)\n",
    "            _, solSteps, _ = computeSolSteps(linkMajor(B_new2))\n",
    "            c_final = c\n",
    "    \n",
    "    \n",
    "        T = B2T(B_new2)\n",
    "        #pprint(B_new2)\n",
    "        #print(mechType + str(i))\n",
    "        #pprint(solSteps)\n",
    "        \n",
    "\n",
    "\n",
    "        saveDir = os.path.abspath(\"/gpfs/scratch/raytang/outputs-8bar/\" + typesList[index] + str(i))\n",
    "        saveDirNpy = os.path.abspath(\"/gpfs/scratch/raytang/outputs-8bar/\" + typesList[index] + str(i) + \"-npy\")\n",
    "        saveDirWalking = os.path.abspath(\"/gpfs/scratch/raytang/outputs-8bar/walking_\" + typesList[index])\n",
    "        saveDirWalkingPlot = os.path.abspath(\"/gpfs/scratch/raytang/outputs-8bar/walking_plot_\" + typesList[index])\n",
    "        \n",
    "        # ADD THESE LINES TO CREATE DIRECTORIES:\n",
    "        os.makedirs(saveDir, exist_ok=True)\n",
    "        os.makedirs(saveDirNpy, exist_ok=True)\n",
    "        os.makedirs(saveDirWalking, exist_ok=True)  # This is the missing one!\n",
    "        os.makedirs(saveDirWalkingPlot, exist_ok=True)\n",
    "            \n",
    "        distStore = [np.zeros(int(55))]\n",
    "    \n",
    "        if not os.path.exists(saveDir):\n",
    "            os.mkdir(saveDir)\n",
    "    \n",
    "        if not os.path.exists(saveDirNpy):\n",
    "            os.mkdir(saveDirNpy)\n",
    "    \n",
    "        #for initState in tqdm(initStates):\n",
    "        for initState in tqdm(initStates[:NUM_MECHS]):\n",
    "            coord = np.round(initState, 3).reshape((int(22/2),2))\n",
    "            dist = calc_dist(coord)\n",
    "    \n",
    "            if max(dist) > 10:\n",
    "                continue\n",
    "    \n",
    "            if np.any(np.all(dist == distStore, axis=1)):\n",
    "                continue\n",
    "    \n",
    "            distStore.append(dist)\n",
    "            param = coord.tolist()\n",
    "            name = str(param).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    \n",
    "            exampleData = {\n",
    "                'T': T, \n",
    "                'solSteps': solSteps, \n",
    "                'params': param,\n",
    "                'speedScale':speedscale, # 1 \n",
    "                'steps':steps, # 360 \n",
    "                'relativeTolerance':0.1 \n",
    "            }\n",
    "    \n",
    "            # The transformation \n",
    "            #np.save(saveDir + name + ' ' + types[index], param)\n",
    "    \n",
    "            batch.append(exampleData)\n",
    "            batchSaveStr.append(saveDir + '/' + name + ' ' + typesList[index] + str(i) + ' ')\n",
    "            batchSaveNpyStr.append(saveDirNpy + '/' + name + ' ' + typesList[index] + str(i) + ' ')\n",
    "    \n",
    "            if len(batch) >= batchCount:\n",
    "                #print(batch[0], '\\n', batch[1])\n",
    "                #print(batchSaveStr[0], '\\n', batchSaveStr[1])\n",
    "                try:\n",
    "                    temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "                    time.sleep(0.02)\n",
    "                except ValueError as v:\n",
    "                    for i in range(3):\n",
    "                        time.sleep(2)\n",
    "                        try:\n",
    "                            temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "                            break\n",
    "                        except ValueError as v2:\n",
    "                            errCtr += 1\n",
    "                for i in range(len(temp)):\n",
    "                    P = np.array(temp[i]['poses'])\n",
    "                    np.save(batchSaveNpyStr[i] + '.npy', P)\n",
    "                    #reak\n",
    "                    try:\n",
    "                        if len(P.shape) >= 1:\n",
    "                            if P.shape[0] >= minsteps:\n",
    "                                # do normalization, also get the transformation parameters. \n",
    "                                # also the paras are saved instead of MP (M: tranformation matrix, P: points in the matrix)\n",
    "                                # This is just to avoid decimal difference problem \n",
    "                                imageMat, transParamSet, success = process_mech_102723(P, 10)\n",
    "                                if success:\n",
    "                                    #Tstr = np.array2string(np.round(transParamSet, 3), precision=3, suppress_small=True).replace(\"[\", \"\").replace(\"]\", \"\") # Wei asked for this part\n",
    "                                    #Tstr = re.sub('\\s+', ' ', Tstr) # to replace multiple sequential spaces together\n",
    "                                    #binary_data = np.uint8(imageMat[:,:,0]) * 255\n",
    "                                    #img = Image.fromarray(binary_data)\n",
    "                                    #img.save(batchSaveStr[i] + Tstr + '.jpg')\n",
    "                                    #plt.imshow(imageMat)\n",
    "                                    #plt.savefig(batchSaveStr[i] + Tstr + '.jpg')\n",
    "                                    #plt.clf()\n",
    "                                    normalized_coords = normalize_data_122223(P[:,10,:], scaling=3.5)[0]\n",
    "                    \n",
    "                                    pca_output = detect_flat_via_pca(normalized_coords)\n",
    "                                    sharp, kappa = has_sharp_edges(normalized_coords, curvature_threshold=150.0)\n",
    "                                    self_intersecting = has_self_intersections(resample_uniform(normalized_coords, 512))\n",
    "                                    \n",
    "                                    joint_coords = np.array(str_to_coords(name))\n",
    "                                    ground_clearance = ground_clearance_check(\n",
    "                                        resample_uniform(P[:,10,:], 512),\n",
    "                                        joint_coords,\n",
    "                                        pca_output['flat_indices']\n",
    "                                    )\n",
    "\n",
    "                                    is_closed_curve = is_curve_closed(normalized_coords, tolerance=0.1)\n",
    "\n",
    "                    \n",
    "                                    # Check walking criteria\n",
    "                                    if (pca_output['is_flat_enough'] and is_closed(normalized_coords) and \n",
    "                                        (not sharp) and ground_clearance and (not self_intersecting) and is_closed_curve):\n",
    "                                        \n",
    "                                        Tstr = np.array2string(np.round(transParamSet, 3), precision=3, suppress_small=True).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "                                        Tstr = re.sub('\\s+', ' ', Tstr)\n",
    "                                        binary_data = np.uint8(imageMat[:,:,0]) * 255\n",
    "                                        img = Image.fromarray(binary_data)\n",
    "                    \n",
    "                                        # Save walking mechanism\n",
    "                                        img.save(saveDirWalking + \"/\" + name + ' ' + typesList[index] + ' ' + Tstr + '.jpg')\n",
    "                                        save_flat_fit_with_joints(\n",
    "                                            resample_uniform(P[:,10,:], 512), \n",
    "                                            pca_output['flat_indices'], \n",
    "                                            joint_coords, \n",
    "                                            saveDirWalkingPlot, \n",
    "                                            f\"{name} {Tstr}\"\n",
    "                                        )\n",
    "                                        print(f\"savedwalking to: {str(saveDirWalking + '/' + name + ' ' + typesList[index] + ' ' + Tstr + '.jpg')}\")\n",
    "                                        \n",
    "                                        result = {\n",
    "                                            'type': typesList[index],\n",
    "                                            'params': param,\n",
    "                                            'flat_fraction': pca_output['flat_fraction'],\n",
    "                                            'max_run': pca_output['max_run'],\n",
    "                                            'orientation_deg': pca_output['orientation_deg'],\n",
    "                                            'sharp': sharp,\n",
    "                                            'ground_clearance': ground_clearance\n",
    "                                        }\n",
    "    \n",
    "    \n",
    "                    except ValueError as v:\n",
    "                        print(v)\n",
    "                    except FileNotFoundError as f:\n",
    "                        print(f)\n",
    "                batch = []\n",
    "                batchSaveStr = []\n",
    "                batchSaveNpyStr = []\n",
    "    \n",
    "        if len(batch) >= batchCount:\n",
    "            #print(batch[0], '\\n', batch[1])\n",
    "            #print(batchSaveStr[0], '\\n', batchSaveStr[1])\n",
    "            try:\n",
    "                temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "                time.sleep(0.02)\n",
    "            except ValueError as v:\n",
    "                for i in range(3):\n",
    "                    time.sleep(2)\n",
    "                    try:\n",
    "                        temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(batch)).json()\n",
    "                        break\n",
    "                    except ValueError as v2:\n",
    "                            errCtr += 1\n",
    "            for i in range(len(temp)):\n",
    "                P = np.array(temp[i]['poses']) \n",
    "                np.save(batchSaveNpyStr[i] + '.npy', P)\n",
    "                #print(P.shape)\n",
    "                #reak\n",
    "                try:\n",
    "                    if len(P.shape) >= 1:\n",
    "                        if P.shape[0] >= minsteps:\n",
    "                            # do normalization, also get the transformation parameters. \n",
    "                            # also the paras are saved instead of MP (M: tranformation matrix, P: points in the matrix)\n",
    "                            # This is just to avoid decimal difference problem \n",
    "                            imageMat, transParamSet, success = process_mech_102723(P, couplerCurveIndex)\n",
    "                            if success:\n",
    "    \n",
    "                                normalized_coords = normalize_data_122223(P[:,10,:], scaling=3.5)[0]\n",
    "                    \n",
    "                                pca_output = detect_flat_via_pca(normalized_coords)\n",
    "                                sharp, kappa = has_sharp_edges(normalized_coords, curvature_threshold=150.0)\n",
    "                                self_intersecting = has_self_intersections(resample_uniform(normalized_coords, 512))\n",
    "                                \n",
    "                                joint_coords = np.array(str_to_coords(name))\n",
    "                                ground_clearance = ground_clearance_check(\n",
    "                                    resample_uniform(P[:, 10 ,:], 512),\n",
    "                                    joint_coords,\n",
    "                                    pca_output['flat_indices']\n",
    "                                )\n",
    "\n",
    "                                is_closed_curve = is_curve_closed(normalized_coords, tolerance=0.1)\n",
    "                \n",
    "                                # Check walking criteria\n",
    "                                if (pca_output['is_flat_enough'] and is_closed(normalized_coords) and \n",
    "                                    (not sharp) and ground_clearance and (not self_intersecting) and is_closed_curve):\n",
    "                                    \n",
    "                                    Tstr = np.array2string(np.round(transParamSet, 3), precision=3, suppress_small=True).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "                                    Tstr = re.sub('\\s+', ' ', Tstr)\n",
    "                                    binary_data = np.uint8(imageMat[:,:,0]) * 255\n",
    "                                    img = Image.fromarray(binary_data)\n",
    "                \n",
    "                                    # Save walking mechanism\n",
    "                                    img.save(saveDirWalking + \"/\" + name + ' ' + typesList[index] + ' ' + Tstr + '.jpg')\n",
    "                                    save_flat_fit_with_joints(\n",
    "                                        resample_uniform(P[:,10,:], 512), \n",
    "                                        pca_output['flat_indices'], \n",
    "                                        joint_coords, \n",
    "                                        saveDirWalkingPlot, \n",
    "                                        f\"{name} {Tstr}\"\n",
    "                                    )\n",
    "                                    print(f\"savedwalking to: {str(saveDirWalking + '/' + name + ' ' + typesList[index] + ' ' + Tstr + '.jpg')}\")\n",
    "                                    \n",
    "                                    result = {\n",
    "                                        'type': typesList[mechType],\n",
    "                                        'params': param,\n",
    "                                        'flat_fraction': pca_output['flat_fraction'],\n",
    "                                        'max_run': pca_output['max_run'],\n",
    "                                        'orientation_deg': pca_output['orientation_deg'],\n",
    "                                        'sharp': sharp,\n",
    "                                        'ground_clearance': ground_clearance\n",
    "                                    }\n",
    "                except ValueError as v:\n",
    "                    print(v)\n",
    "                except FileNotFoundError as f:\n",
    "                    print(f)\n",
    "            batch = []\n",
    "            batchSaveStr = []\n",
    "            batchSaveNpyStr = []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Jupyter] *",
   "language": "python",
   "name": "conda-env-Jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
