{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(73761) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.5.4)\n",
      "Requirement already satisfied: torch>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch_lightning) (2.7.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch_lightning) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>5.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n",
      "Requirement already satisfied: torchmetrics>0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch_lightning) (1.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch_lightning) (25.0)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch_lightning) (4.14.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch_lightning) (0.15.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.12.15)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (57.4.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
      "Requirement already satisfied: numpy>1.20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchmetrics>0.7.0->pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.20.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm \n",
    "from model import VAE\n",
    "import torch\n",
    "import cv2\n",
    "import json \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv_stack): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(11, 11), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "      (4): ReLU()\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (7): ReLU()\n",
       "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (9): Flatten()\n",
       "      (10): Linear(in_features=8192, out_features=50, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (inverse_conv_stack): Sequential(\n",
       "      (0): Linear(in_features=25, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): UnFlatten()\n",
       "      (3): ConvTranspose2d(16, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (4): ReLU()\n",
       "      (5): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "      (6): ReLU()\n",
       "      (7): ConvTranspose2d(64, 32, kernel_size=(11, 11), stride=(2, 2), padding=(1, 1))\n",
       "      (8): ReLU()\n",
       "      (9): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(1, 1), padding=(3, 3))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "latentDim = 25\n",
    "checkpoint_path = \"./ckpt_files/anar_lat_25_052324.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "model = VAE(latentDim)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from string \n",
    "def process_string_mech(dir, toNpy = True):\n",
    "    # I do not know why but this works for windows os. You may need to change this if you are using linux/macbook\n",
    "    # Zhijie: you can test using strings like: \n",
    "    # ./outputs-4bar/-0.001 2.728 5.504 -1.565 -5.632 -2.481 -8.711 9.682 1.320 -5.630 -7.171 3.601 RRRP  0.42 0.026 0.732 -0.026 0.42 2.011 0. 0. 1. .jpg\n",
    "    input_string = dir.split('\\\\')[-1].split('.j')[0] \n",
    "    \n",
    "    # Split the string by spaces\n",
    "    parts = input_string.split()\n",
    "    \n",
    "    # Initialize lists to hold floats\n",
    "    floats_before = []\n",
    "    floats_after = []\n",
    "    letter_string = None\n",
    "    \n",
    "    # Iterate over parts to separate floats and the letter string\n",
    "    for part in parts:\n",
    "        try:\n",
    "            # Try to convert part to float\n",
    "            num = float(part)\n",
    "            # Add to floats_before if letter_string is not yet found\n",
    "            if letter_string is None:\n",
    "                floats_before.append(num)\n",
    "            else:\n",
    "                floats_after.append(num)\n",
    "        except ValueError:\n",
    "            # If conversion fails, this part is the letter string\n",
    "            letter_string = part\n",
    "    \n",
    "    if toNpy:\n",
    "        floats_before = np.array(floats_before).reshape((-1, 2))\n",
    "        floats_after = np.matrix(floats_after).reshape((3, 3))\n",
    "    \n",
    "    #if len(floats_before) != 10: # security check... you should change this for your specific mechanism. \n",
    "    #    print('you got fucked', dir, '\\n' , floats_before, '\\n')\n",
    "    return floats_before, letter_string, floats_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt1T1A1 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 2629.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what? [-8.97, -6.076, -2.308, -2.684, -3.672, -6.697, -7.167, -1.136, -9.162, 7.488, 3.395, -2.455, 9.035, -6.345, 4.711, -0.238, 0.061, -1.342, -0.061, -0.238, -0.471, 0.0, 0.0, 1.0]\n",
      "what? [5.025, -7.393, -1.63, -5.362, -9.128, 2.599, 4.324, -1.805, 8.738, -7.403, 8.117, 8.784, 7.383, -4.241, -2.817, 0.295, -0.219, 2.727, -0.219, -0.295, -0.158, 0.0, 0.0, 1.0]\n",
      "what? [1.73, 0.981, 0.305, -0.63, -4.057, 8.77, -9.663, -5.501, 1.657, 7.623, 2.576, -8.282, 3.827, 7.777, -0.213, 0.157, 0.153, 0.93, -0.153, 0.157, 1.571, 0.0, 0.0, 1.0]\n",
      "what? [4.882, 2.263, -1.785, 4.719, -3.952, -6.348, -4.054, -3.008, 2.802, 6.859, -5.769, -9.77, 3.305, -8.559, -8.594, -0.339, -0.034, -0.407, -0.034, 0.339, 1.051, 0.0, 0.0, 1.0]\n",
      "what? [-3.145, -0.976, -8.783, -3.962, -7.213, 1.651, 4.983, 6.25, 1.705, -4.848, 7.88, -6.312, -1.391, 0.108, 7.81, -0.183, -0.081, -0.811, 0.081, -0.183, 1.537, 0.0, 0.0, 1.0]\n",
      "what? [-4.71, -6.75, -6.12, 5.56, 9.145, 1.014, -5.67, -4.436, -6.909, -2.228, 0.68, 9.77, 9.76, -4.824, 5.556, -0.561, 0.545, -4.832, -0.545, -0.561, 0.083, 0.0, 0.0, 1.0]\n",
      "what? [0.022, 2.391, -1.439, 4.444, -0.302, -4.063, -9.434, -2.69, -0.128, 3.866, -4.585, 4.606, -6.819, 9.286, 4.968, 0.11, 0.359, 0.189, -0.359, 0.11, 2.596, 0.0, 0.0, 1.0]\n",
      "what? [2.302, 4.459, 7.312, -7.0, -1.167, -9.384, -7.368, -4.486, 6.241, 0.13, -5.209, 4.271, 5.278, 8.432, -9.363, -0.194, -0.1, 0.349, -0.1, 0.194, 3.055, 0.0, 0.0, 1.0]\n",
      "what? [6.758, -4.654, -0.548, 6.22, -3.564, 7.475, -0.347, 9.16, -4.311, 2.781, 2.26, -1.965, 5.458, 2.108, -8.385, -0.698, 1.059, 8.213, -1.059, -0.698, -3.418, 0.0, 0.0, 1.0]\n",
      "what? [8.119, -6.552, -1.959, 4.596, -7.226, -1.4, -8.728, -7.557, -5.614, -7.586, 4.875, -5.127, -4.123, 3.553, -2.113, 0.144, -0.12, -0.441, -0.12, -0.144, -0.79, 0.0, 0.0, 1.0]\n",
      "what? [-7.1, 3.142, 2.163, -5.953, 5.122, -5.143, -1.225, 0.589, 6.009, 9.775, -2.209, 6.357, 5.933, 5.074, -1.024, 0.086, 0.19, -0.286, -0.19, 0.086, 0.769, 0.0, 0.0, 1.0]\n",
      "what? [6.383, 3.159, 7.327, -0.553, -5.511, 9.615, 3.811, -6.638, 5.964, -3.158, -4.598, 7.263, -4.161, 3.194, 9.904, -0.422, -0.16, 2.181, 0.16, -0.422, 3.426, 0.0, 0.0, 1.0]\n",
      "what? [5.162, -7.007, 1.211, -10.0, -5.957, -4.417, -3.737, -7.411, -2.848, 8.962, 0.701, 2.898, 0.64, 2.622, -8.348, -0.03, 0.209, 1.085, -0.209, -0.03, 0.404, 0.0, 0.0, 1.0]\n",
      "what? [-3.386, 4.037, 5.197, 2.271, 3.844, 3.114, -3.044, 7.737, -5.521, -2.215, -5.721, 4.156, 8.805, -8.996, 1.595, -0.232, -0.236, 1.07, -0.236, 0.232, -0.409, 0.0, 0.0, 1.0]\n",
      "what? [2.093, -9.072, -0.695, 1.776, -2.169, -1.447, -4.562, 1.355, 7.619, 8.585, -1.466, -1.658, 7.211, 1.914, 4.286, -0.212, -0.708, 4.902, -0.708, 0.212, 0.38, 0.0, 0.0, 1.0]\n",
      "what? [4.227, -2.6, 4.767, -6.838, 5.573, -2.409, -4.78, 0.893, 9.549, -9.406, -0.581, 0.801, -5.467, 3.065, -4.193, 0.202, -0.018, 1.707, 0.018, 0.202, -0.131, 0.0, 0.0, 1.0]\n",
      "what? [-8.357, -9.774, 9.509, 5.194, -2.84, -6.538, -9.411, 2.824, -1.114, -0.165, -2.315, 9.647, 3.791, -4.763, -1.249, 0.242, 0.067, -0.552, 0.067, -0.242, 0.279, 0.0, 0.0, 1.0]\n",
      "what? [-6.103, -5.137, 2.24, 9.52, 9.375, 0.13, 0.795, -7.398, -9.891, 6.433, 7.261, 4.437, -1.639, 1.182, -8.982, 0.308, -0.012, -1.937, 0.012, 0.308, 2.937, 0.0, 0.0, 1.0]\n",
      "what? [-0.471, 3.965, 4.541, 1.936, 6.233, -7.549, 9.97, 6.442, -0.816, 9.007, -7.466, 9.585, 2.781, 7.683, -5.218, -0.055, -0.396, -0.618, -0.396, 0.055, 5.807, 0.0, 0.0, 1.0]\n",
      "what? [-1.328, 5.381, 9.526, -9.595, -5.79, 8.994, 0.556, 6.007, 4.342, -9.99, -1.289, 1.084, 6.976, -8.871, 0.794, -0.234, 0.033, -1.949, -0.033, -0.234, -0.417, 0.0, 0.0, 1.0]\n",
      "what? [4.622, 4.275, 5.744, 5.712, -5.906, 7.667, 9.168, 9.396, -2.077, 3.844, -4.597, -2.921, -2.111, -6.16, -2.533, -0.315, -0.498, -1.661, 0.498, -0.315, 2.153, 0.0, 0.0, 1.0]\n",
      "Watt1T2A1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt1T3A1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt1T1A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt1T2A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt1T3A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt2T1A1 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 3508.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what? [-4.73, 3.886, -0.894, -3.327, 2.436, -5.043, 9.892, 4.339, -8.286, -0.0, -9.041, -1.135, -5.334, -1.26, 3.863, -0.597, -0.09, 1.38, 0.09, -0.597, 2.283, 0.0, 0.0, 1.0]\n",
      "what? [5.783, -6.407, 9.248, 5.562, -8.056, 0.516, 7.689, 3.93, -0.871, -5.639, -7.315, -1.71, 6.003, -8.002, -0.2, -0.407, 0.089, -2.277, 0.089, 0.407, 1.706, 0.0, 0.0, 1.0]\n",
      "what? [-5.003, -6.912, -1.174, 4.177, 3.589, 3.657, -3.447, -1.325, -0.094, 6.182, -5.634, 4.922, -1.01, -7.752, -9.003, 0.096, 0.13, -0.785, 0.13, -0.096, 0.38, 0.0, 0.0, 1.0]\n",
      "what? [6.742, 3.755, -0.226, -9.845, 5.834, -1.528, 0.457, -6.514, -9.574, 7.997, -2.646, 5.961, -5.085, 3.775, 8.983, 0.363, 0.093, 1.275, 0.093, -0.363, 3.305, 0.0, 0.0, 1.0]\n",
      "what? [9.808, -5.37, 3.529, -4.983, -9.103, -7.649, 2.377, 0.918, -8.409, 6.46, 6.652, 2.438, -1.247, -3.493, 6.479, 0.752, -0.058, 0.242, 0.058, 0.752, -4.222, 0.0, 0.0, 1.0]\n",
      "what? [2.748, 1.532, -3.129, -7.547, -3.462, -8.879, -6.131, 5.923, -0.96, 6.399, 6.286, 8.896, -0.011, -4.132, -2.898, -2.134, -0.893, -10.19, -0.893, 2.134, 2.097, 0.0, 0.0, 1.0]\n",
      "what? [-4.77, 3.228, 0.086, 0.762, 1.394, -7.043, 3.759, 7.501, -1.601, -3.423, -2.66, -7.87, 1.146, -0.307, 9.395, -0.232, -0.371, 1.319, -0.371, 0.232, 0.459, 0.0, 0.0, 1.0]\n",
      "what? [9.476, 9.002, -7.255, -5.282, 9.844, 6.103, -9.732, -6.356, 6.391, -4.848, -5.341, 3.742, 2.354, -1.534, 4.775, -0.081, 0.069, -0.648, 0.069, 0.081, -1.427, 0.0, 0.0, 1.0]\n",
      "what? [0.846, 3.079, 5.288, -9.881, 8.651, -1.976, -7.418, 2.528, -0.91, 7.037, -9.076, -0.149, -4.794, 5.153, 2.3, -0.092, 0.353, -1.352, -0.353, -0.092, 1.802, 0.0, 0.0, 1.0]\n",
      "what? [4.837, -1.526, -5.355, -3.967, 6.696, -1.21, 7.421, 7.828, 0.732, -0.783, 9.902, 6.575, -2.111, -6.628, 1.935, -1.185, -0.066, -4.737, -0.066, 1.185, -2.45, 0.0, 0.0, 1.0]\n",
      "what? [-1.926, 0.217, -6.036, 2.364, -6.64, 1.07, 4.923, -4.767, -8.561, 9.084, -7.255, 4.825, -5.617, 4.561, 0.3, -0.439, 0.181, 2.401, -0.181, -0.439, 0.511, 0.0, 0.0, 1.0]\n",
      "what? [1.429, -9.269, -4.999, 5.271, -4.534, -0.994, 8.148, -7.771, -0.205, 7.109, 9.552, 7.974, -4.305, -9.184, 8.926, 0.145, -0.043, -0.597, -0.043, -0.145, 0.694, 0.0, 0.0, 1.0]\n",
      "what? [5.498, 2.751, 7.064, -5.433, 2.139, 7.097, -1.55, -7.856, 6.871, 4.472, 9.375, -4.906, -3.77, -8.129, 3.991, -0.346, -0.37, -1.731, 0.37, -0.346, 4.835, 0.0, 0.0, 1.0]\n",
      "what? [-2.278, 0.589, -9.48, 3.999, -9.185, 9.615, 4.048, 1.73, -8.027, -7.21, -1.623, 3.567, -0.58, 6.667, -7.547, 0.144, 0.369, 0.522, 0.369, -0.144, -3.744, 0.0, 0.0, 1.0]\n",
      "what? [8.659, -8.14, 0.672, 6.441, -1.477, 8.729, -7.904, -1.445, -9.537, 1.845, -2.39, 4.18, 4.872, 8.073, -3.125, 0.233, -0.337, -0.721, 0.337, 0.233, -1.084, 0.0, 0.0, 1.0]\n",
      "what? [0.672, 5.733, -4.162, 2.456, 1.512, 3.216, 9.595, -3.772, 4.63, 1.249, 9.1, -7.637, 9.664, -2.938, -4.326, -0.966, -0.574, -5.461, -0.574, 0.966, 1.206, 0.0, 0.0, 1.0]\n",
      "what? [7.473, -4.463, 7.932, -6.746, -2.861, -5.374, -0.822, 8.347, -6.657, 6.16, -3.856, -2.745, -7.53, 4.887, 4.187, 0.26, -0.892, -0.927, 0.892, 0.26, -5.644, 0.0, 0.0, 1.0]\n",
      "what? [-0.72, -6.089, -7.311, -9.529, -8.25, -3.393, -5.954, 5.874, -9.381, 9.287, 9.075, 0.805, -5.737, -1.578, 3.355, -0.193, -0.085, -0.528, 0.085, -0.193, 0.107, 0.0, 0.0, 1.0]\n",
      "what? [9.706, 6.075, 9.868, -5.962, -3.587, -1.644, -3.759, 0.164, -7.114, -5.438, 4.15, 4.283, 7.715, 7.57, -2.634, -0.258, -0.416, -0.639, -0.416, 0.258, 3.748, 0.0, 0.0, 1.0]\n",
      "what? [-2.904, 5.028, 8.374, -7.434, -5.586, -5.204, -9.998, 5.631, 1.139, -6.591, 2.703, -5.326, -6.352, -1.175, 2.014, -0.323, 0.087, -1.725, -0.087, -0.323, -0.263, 0.0, 0.0, 1.0]\n",
      "what? [-4.147, -0.586, -7.37, 6.878, 7.199, -3.31, 4.912, -2.072, -2.521, 3.021, 5.452, 2.115, -0.019, 9.675, -9.304, -0.175, -0.377, 1.188, -0.377, 0.175, 5.453, 0.0, 0.0, 1.0]\n",
      "what? [-3.07, 9.166, 0.947, 5.163, -8.446, 0.245, -0.094, 7.64, 9.293, -9.684, 4.749, -2.756, 4.439, 1.383, -5.183, -0.383, -0.24, 0.265, -0.24, 0.383, 1.865, 0.0, 0.0, 1.0]\n",
      "what? [6.221, 5.833, 0.398, -6.521, 0.428, -8.361, 3.454, 0.999, -7.585, 5.089, -8.827, 7.865, 8.896, -8.407, -0.216, -1.129, -0.369, -8.08, 0.369, -1.129, 2.763, 0.0, 0.0, 1.0]\n",
      "what? [-5.728, 1.869, 8.273, 7.427, -6.543, -6.783, 5.029, 0.871, -7.439, -5.476, -8.627, 3.379, -6.336, 9.215, 8.147, 0.065, 0.152, 0.824, 0.152, -0.065, 1.363, 0.0, 0.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt2T2A1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt2T1A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watt2T2A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph1T1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph1T2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph1T3 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 3273.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what? [-5.582, -8.219, -4.177, -9.572, -1.611, 2.36, -6.506, 6.758, -1.373, -2.019, 3.141, -6.669, 3.874, 4.71, -7.11, 0.114, 0.801, 2.729, -0.801, 0.114, 4.76, 0.0, 0.0, 1.0]\n",
      "what? [-8.744, -6.308, -5.924, -4.19, -7.561, -0.061, -1.982, 1.821, 4.685, 5.088, -7.136, -5.499, 7.277, 8.292, -5.976, 0.134, -0.13, -0.574, -0.13, -0.134, 0.082, 0.0, 0.0, 1.0]\n",
      "what? [9.468, 0.796, 2.509, 6.824, 8.907, -8.548, -2.975, 9.344, 1.499, 7.093, -8.834, 4.498, -3.813, 1.968, -5.851, 0.151, -0.107, 2.124, 0.107, 0.151, 1.628, 0.0, 0.0, 1.0]\n",
      "what? [1.703, -5.883, -3.578, 6.099, 8.078, 1.539, -7.265, 2.88, -0.663, 6.534, -7.068, 6.456, -5.201, 0.159, 4.01, -0.779, 0.54, -5.375, 0.54, 0.779, -2.606, 0.0, 0.0, 1.0]\n",
      "what? [-3.424, 9.721, -1.603, -8.787, -6.317, 7.856, -2.911, 1.23, -2.595, 6.697, 4.771, -1.438, 4.739, 6.827, -8.685, -0.018, 0.33, 5.676, -0.33, -0.018, 2.355, 0.0, 0.0, 1.0]\n",
      "what? [6.64, -1.144, -8.955, -5.61, 2.072, 2.744, -7.819, 0.694, 4.549, 8.848, 1.221, 4.126, -8.826, -1.115, -1.962, -0.117, 0.154, -0.484, 0.154, 0.117, 0.839, 0.0, 0.0, 1.0]\n",
      "what? [-4.805, 2.246, 5.105, 8.092, -3.787, -5.915, -5.805, -5.324, 9.39, -0.125, -7.488, 1.137, -9.603, -1.241, -9.395, -0.681, 0.31, 5.453, 0.31, 0.681, 7.16, 0.0, 0.0, 1.0]\n",
      "what? [7.878, -6.173, 1.581, -1.185, 6.65, -7.01, 2.729, -2.797, 0.731, -7.157, 4.842, -2.424, -3.092, 3.411, 3.714, -0.023, 0.301, -1.003, -0.301, -0.023, 0.271, 0.0, 0.0, 1.0]\n",
      "what? [-0.722, -8.318, 1.403, 6.422, -6.208, -0.083, -1.215, -2.467, 7.702, -2.511, -7.795, -4.834, 2.578, -6.098, 0.973, 0.194, -0.073, -1.62, 0.073, 0.194, 1.744, 0.0, 0.0, 1.0]\n",
      "what? [5.978, 7.292, -7.91, 1.547, 6.485, 3.766, 9.75, -4.874, -8.932, -7.572, -7.692, 6.664, -1.362, -1.421, -6.922, 0.488, -0.03, -2.867, 0.03, 0.488, 3.839, 0.0, 0.0, 1.0]\n",
      "what? [-4.239, -2.265, 0.312, 6.42, 7.461, -6.861, 3.913, -0.248, 9.635, -7.963, 8.361, -9.264, -0.873, -3.657, -8.243, -0.378, -0.071, -2.189, -0.071, 0.378, 4.227, 0.0, 0.0, 1.0]\n",
      "what? [6.931, 6.927, 2.901, 3.775, -5.817, 0.214, 2.051, -0.891, -3.954, -5.488, 5.606, -5.386, 0.324, -4.738, -1.125, 0.489, -1.26, -2.092, 1.26, 0.489, 7.905, 0.0, 0.0, 1.0]\n",
      "what? [5.883, -5.258, -4.212, 8.561, 5.006, -9.951, 7.316, -2.064, -0.982, 2.432, -9.33, -7.976, -7.357, 4.008, 9.82, -0.156, 0.006, 1.277, -0.006, -0.156, 1.132, 0.0, 0.0, 1.0]\n",
      "what? [4.219, 4.137, -9.969, -4.035, 9.382, -3.583, 4.649, 2.143, -2.848, -0.584, -0.016, -9.917, 2.138, -6.425, 1.894, -0.135, 0.436, -3.951, 0.436, 0.135, 3.651, 0.0, 0.0, 1.0]\n",
      "what? [9.515, -2.288, 9.531, -9.619, 7.276, -6.581, -6.259, -4.385, -9.563, -4.887, 2.4, 9.443, -3.446, 9.174, 3.585, 0.13, -0.111, 2.113, -0.111, -0.13, 0.655, 0.0, 0.0, 1.0]\n",
      "what? [-0.485, -6.534, -4.553, 5.428, 4.194, -8.787, 1.279, 7.145, -7.246, 2.247, -4.146, 6.753, -9.45, -1.418, -0.326, 0.109, 0.347, -1.919, 0.347, -0.109, 0.507, 0.0, 0.0, 1.0]\n",
      "what? [8.509, 5.359, -0.872, 3.948, -7.071, 9.31, -9.376, 1.172, 0.798, 1.473, -3.453, 3.183, 6.206, -5.617, -2.748, -0.112, -0.4, 0.951, -0.4, 0.112, -1.834, 0.0, 0.0, 1.0]\n",
      "what? [8.824, -9.709, -4.87, -5.254, -4.857, 1.066, -1.505, 7.757, 9.079, -1.906, -1.527, 6.431, 4.825, 8.44, 2.715, -0.633, 0.617, 1.711, -0.617, -0.633, 6.774, 0.0, 0.0, 1.0]\n",
      "what? [0.598, -9.768, -6.323, -9.926, 3.199, -8.225, -3.271, -0.038, 5.75, -1.601, 9.762, -1.32, -8.137, 2.561, -4.331, 0.266, 0.143, 2.509, -0.143, 0.266, 2.426, 0.0, 0.0, 1.0]\n",
      "what? [0.484, 4.985, 8.281, -5.772, -3.006, 7.777, 8.219, -4.215, 8.228, 3.251, -7.788, 6.741, 5.304, -1.896, -9.583, 0.025, -0.154, 0.924, 0.154, 0.025, 0.896, 0.0, 0.0, 1.0]\n",
      "what? [0.712, 8.963, 2.67, 5.139, -6.753, 2.021, -7.186, -4.671, -0.076, 2.888, -9.226, 0.727, 9.479, -3.08, -5.852, 0.654, -1.423, -6.827, 1.423, 0.654, 8.15, 0.0, 0.0, 1.0]\n",
      "what? [3.43, 5.418, -0.818, -9.026, 8.29, 2.87, 2.037, 6.593, -4.788, -4.975, 4.489, -7.287, -2.107, -7.769, -4.532, -0.056, -0.279, 1.143, 0.279, -0.056, 2.443, 0.0, 0.0, 1.0]\n",
      "what? [-9.409, -0.125, -9.324, -3.939, 6.048, 0.166, 6.04, 7.665, 8.672, 7.213, 0.405, 3.997, -0.626, 2.249, 4.554, -0.553, -2.327, 9.519, -2.327, 0.553, 2.783, 0.0, 0.0, 1.0]\n",
      "Steph2T1A1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph2T2A1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph3T1A1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph3T2A1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph3T1A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph3T2A2 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 2648.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what? [5.664, 4.202, 1.993, -9.898, -8.593, -5.596, 6.222, -7.004, -8.254, -7.928, 8.614, 8.297, 0.748, 3.225, -4.895, -0.263, -0.351, 2.257, -0.351, 0.263, 3.656, 0.0, 0.0, 1.0]\n",
      "what? [7.521, -6.734, 1.6, 2.543, -5.065, -7.762, 3.656, -8.179, -6.325, 1.663, -6.562, 0.228, -7.117, -1.362, -5.246, 0.361, 0.007, 0.722, 0.007, -0.361, -1.104, 0.0, 0.0, 1.0]\n",
      "what? [1.428, 7.41, -0.378, -1.18, -3.045, 9.99, -9.22, 6.573, 6.306, 4.828, 8.384, 0.662, 0.864, -1.569, 6.324, 0.927, 0.585, -0.527, -0.585, 0.927, -4.284, 0.0, 0.0, 1.0]\n",
      "what? [-4.762, -5.742, -1.571, -1.282, 4.906, 7.42, -4.003, 4.721, 4.46, 5.841, -5.647, -4.369, -2.641, 8.341, 3.577, -0.788, -0.341, 7.319, 0.341, -0.788, 0.613, 0.0, 0.0, 1.0]\n",
      "what? [1.935, 3.003, -1.157, 5.249, -8.246, -4.607, -8.14, -4.139, 6.54, -9.739, -2.092, -3.291, 3.863, -3.322, -1.981, -0.174, -0.797, -0.715, 0.797, -0.174, 4.074, 0.0, 0.0, 1.0]\n",
      "what? [-2.803, -3.095, 3.607, -5.461, 8.921, 1.909, 1.57, 0.182, 7.565, -6.675, -5.27, -2.74, -4.587, -3.456, 8.81, 0.096, 1.071, -8.674, -1.071, 0.096, -4.974, 0.0, 0.0, 1.0]\n",
      "what? [-4.29, 7.306, -9.409, -4.171, 2.52, -1.93, 0.805, -5.81, 0.634, 7.016, 8.074, 8.255, 3.425, 5.092, 7.835, -0.113, 0.265, -1.492, -0.265, -0.113, 2.312, 0.0, 0.0, 1.0]\n",
      "Steph2T1A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steph2T2A2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# BSIdictionary update (PRPR)\n",
    "file_path = './KV_468_062324.json'\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    KVdict = json.load(file) \n",
    "\n",
    "image_folder = './outputs-6bar/'\n",
    "\n",
    "setSize = 3000 # len(imgStrings) # determine how many samples for each type. \n",
    "batchSize = 1000\n",
    "four_bar = ['RRRR', 'RRRP', 'RRPR', 'PRPR']  # \n",
    "six_bar  = ['Watt1T1A1', 'Watt1T2A1', 'Watt1T3A1', 'Watt1T1A2', 'Watt1T2A2', 'Watt1T3A2', \n",
    "            'Watt2T1A1', 'Watt2T2A1', 'Watt2T1A2', 'Watt2T2A2', 'Steph1T1', 'Steph1T2',\n",
    "            'Steph1T3', 'Steph2T1A1', 'Steph2T2A1', 'Steph3T1A1', 'Steph3T2A1', 'Steph3T1A2', \n",
    "            'Steph3T2A2', 'Steph2T1A2', 'Steph2T2A2']\n",
    "eight_bar = list(set(KVdict.keys()) - set(four_bar) - set(six_bar))\n",
    "\n",
    "for mechType in six_bar:\n",
    "    batchImg = []\n",
    "    result_zSet = []\n",
    "    result_featSet = []\n",
    "    value = KVdict[mechType]\n",
    "    z_folder = './outputs-z/'\n",
    "    e_folder = './outputs-encoded/'\n",
    "    imgStrings = glob(image_folder + mechType + '/*')\n",
    "    print(mechType, len(imgStrings))\n",
    "    for i in tqdm(range(min(setSize, len(imgStrings)))): \n",
    "        batchImg.append(cv2.imread(imgStrings[i], cv2.IMREAD_GRAYSCALE)/ 255) # This /255 works better than not doing it \n",
    "        floats_before, letter_string, floats_after = process_string_mech(imgStrings[i], toNpy = False)\n",
    "        if len(floats_after) == 6:\n",
    "            floats_after = floats_after + [0, 0, 1]\n",
    "        elif len(floats_after) != 9: \n",
    "            print('what?', floats_after)\n",
    "        \n",
    "        result_featSet.append(np.array(floats_before + [KVdict[letter_string]] + floats_after, dtype= float).flatten().tolist())\n",
    "        if len(batchImg) >= batchSize:\n",
    "            images = torch.from_numpy(np.array([batchImg])).swapaxes(0,1).float().to(device)\n",
    "            x = model.encoder(images)\n",
    "            mean, logvar = x[:, : model.latent_dim], x[:, model.latent_dim :]\n",
    "            z = model.reparameterize(mean, logvar)\n",
    "            z = z.cpu().detach().numpy()\n",
    "            result_zSet.append(z)\n",
    "            batchImg = []\n",
    "\n",
    "    if len(batchImg) > 0:\n",
    "        images = torch.from_numpy(np.array([batchImg])).swapaxes(0,1).float().to(device)\n",
    "        x = model.encoder(images)\n",
    "        mean, logvar = x[:, : model.latent_dim], x[:, model.latent_dim :]\n",
    "        z = model.reparameterize(mean, logvar)\n",
    "        z = z.cpu().detach().numpy()\n",
    "        result_zSet.append(z)\n",
    "        batchImg = []\n",
    "\n",
    "    if len(result_zSet) > 0:\n",
    "        result_zSet = np.concatenate(result_zSet)\n",
    "        date = '062324'\n",
    "\n",
    "        batchZname = z_folder + date + '-z-' + str(int(KVdict[mechType]))\n",
    "        batchEname = e_folder + date + '-encoded-' + str(int(KVdict[mechType]))\n",
    "        np.save(batchZname, np.array(result_zSet))\n",
    "        np.save(batchEname, np.array(result_featSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mresult_featSet\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thing \u001b[38;5;129;01min\u001b[39;00m result_featSet:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(thing) \u001b[38;5;241m!=\u001b[39m length:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "length = len(result_featSet[0])\n",
    "for thing in result_featSet:\n",
    "    if len(thing) != length:\n",
    "        print(thing, len(thing))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
